{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sentence_transformers.losses import CoSENTLoss, MultipleNegativesRankingLoss\n",
    "from my_datasets import Dataset as HFDataset\n",
    "from itertools import islice\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from usearch.index import Index\n",
    "import string\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "from my_datasets import load_dataset\n",
    "\n",
    "\n",
    "from my_datasets import load_dataset\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    SentenceTransformerModelCardData,\n",
    ")\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_name = \"Alibaba-NLP/gte-large-en-v1.5\"\n",
    "model = SentenceTransformer(model_name, trust_remote_code=True)\n",
    "model_ = AutoModel.from_pretrained(model_name, trust_remote_code=True).cuda()\n",
    "tokenizer_ = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load paraphrased misconception\n",
    "df_mis = pd.read_csv(\"data/eedi-paraphrased/misconception_mapping.csv\")\n",
    "orig_mis = (\n",
    "    df_mis[~df_mis[\"MisconceptionAiCreated\"]]\n",
    "    .sort_values(\"MisconceptionId\")[\"MisconceptionText\"]\n",
    "    .tolist()\n",
    ")\n",
    "assert len(orig_mis) == 2587\n",
    "\n",
    "# load paraphrased train\n",
    "df = pd.read_csv(\"data/eedi-paraphrased/train.csv\")\n",
    "df[\"QuestionComplete\"] = (\n",
    "    \"Subject: \"\n",
    "    + df[\"SubjectName\"]\n",
    "    + \". Construct: \"\n",
    "    + df[\"ConstructName\"]\n",
    "    + \". Question: \"\n",
    "    + df[\"QuestionText\"]\n",
    "    + \". Correct answer: \"\n",
    "    + df[\"CorrectText\"]\n",
    "    + \". Wrong answer: \"\n",
    "    + df[\"WrongText\"]\n",
    "    + \".\"\n",
    ")\n",
    "\n",
    "# split to train (w miscons) and val (w/o miscons)\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.7, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(df, groups=df[\"QuestionId\"]))\n",
    "df_train = df.iloc[train_idx].reset_index(drop=True)\n",
    "df_val = df.iloc[val_idx]\n",
    "df_val = df_val[~df_val[\"QuestionAiCreated\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>ConstructId</th>\n",
       "      <th>ConstructName</th>\n",
       "      <th>SubjectId</th>\n",
       "      <th>SubjectName</th>\n",
       "      <th>CorrectChoice</th>\n",
       "      <th>CorrectText</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>WrongChoice</th>\n",
       "      <th>WrongText</th>\n",
       "      <th>MisconceptionId</th>\n",
       "      <th>QuestionId_Answer</th>\n",
       "      <th>QuestionAiCreated</th>\n",
       "      <th>QuestionComplete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>Use the order of operations to carry out calcu...</td>\n",
       "      <td>33</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>A</td>\n",
       "      <td>\\( 3 \\times(2+4)-5 \\)</td>\n",
       "      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Does not need brackets</td>\n",
       "      <td>1672</td>\n",
       "      <td>0_D</td>\n",
       "      <td>False</td>\n",
       "      <td>Subject: BIDMAS. Construct: Use the order of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>Use the order of operations to carry out calcu...</td>\n",
       "      <td>33</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>A</td>\n",
       "      <td>\\( 3 \\times(2+4)-5 \\)</td>\n",
       "      <td>What placement of brackets will result in the ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Does not need brackets</td>\n",
       "      <td>1672</td>\n",
       "      <td>0_D</td>\n",
       "      <td>True</td>\n",
       "      <td>Subject: BIDMAS. Construct: Use the order of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>Use the order of operations to carry out calcu...</td>\n",
       "      <td>33</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>A</td>\n",
       "      <td>\\( 3 \\times(2+4)-5 \\)</td>\n",
       "      <td>In the equation 3 × 2 + 4 - 5, where should br...</td>\n",
       "      <td>D</td>\n",
       "      <td>Does not need brackets</td>\n",
       "      <td>1672</td>\n",
       "      <td>0_D</td>\n",
       "      <td>True</td>\n",
       "      <td>Subject: BIDMAS. Construct: Use the order of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>Use the order of operations to carry out calcu...</td>\n",
       "      <td>33</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>A</td>\n",
       "      <td>\\( 3 \\times(2+4)-5 \\)</td>\n",
       "      <td>How can brackets be arranged in the expression...</td>\n",
       "      <td>D</td>\n",
       "      <td>Does not need brackets</td>\n",
       "      <td>1672</td>\n",
       "      <td>0_D</td>\n",
       "      <td>True</td>\n",
       "      <td>Subject: BIDMAS. Construct: Use the order of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>Use the order of operations to carry out calcu...</td>\n",
       "      <td>33</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>A</td>\n",
       "      <td>\\( 3 \\times(2+4)-5 \\)</td>\n",
       "      <td>Which locations for brackets in the expression...</td>\n",
       "      <td>D</td>\n",
       "      <td>Does not need brackets</td>\n",
       "      <td>1672</td>\n",
       "      <td>0_D</td>\n",
       "      <td>True</td>\n",
       "      <td>Subject: BIDMAS. Construct: Use the order of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15288</th>\n",
       "      <td>1868</td>\n",
       "      <td>2680</td>\n",
       "      <td>Describe a 90° or 270° rotation giving the ang...</td>\n",
       "      <td>93</td>\n",
       "      <td>Rotation</td>\n",
       "      <td>B</td>\n",
       "      <td>Only Paul</td>\n",
       "      <td>Jo and Paul are arguing about how to fully des...</td>\n",
       "      <td>D</td>\n",
       "      <td>Neither is correct</td>\n",
       "      <td>95</td>\n",
       "      <td>1868_D</td>\n",
       "      <td>False</td>\n",
       "      <td>Subject: Rotation. Construct: Describe a 90° o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15289</th>\n",
       "      <td>1868</td>\n",
       "      <td>2680</td>\n",
       "      <td>Describe a 90° or 270° rotation giving the ang...</td>\n",
       "      <td>93</td>\n",
       "      <td>Rotation</td>\n",
       "      <td>B</td>\n",
       "      <td>Only Paul</td>\n",
       "      <td>Jo claims that the rotation from shape P to sh...</td>\n",
       "      <td>D</td>\n",
       "      <td>Neither is correct</td>\n",
       "      <td>95</td>\n",
       "      <td>1868_D</td>\n",
       "      <td>True</td>\n",
       "      <td>Subject: Rotation. Construct: Describe a 90° o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15290</th>\n",
       "      <td>1868</td>\n",
       "      <td>2680</td>\n",
       "      <td>Describe a 90° or 270° rotation giving the ang...</td>\n",
       "      <td>93</td>\n",
       "      <td>Rotation</td>\n",
       "      <td>B</td>\n",
       "      <td>Only Paul</td>\n",
       "      <td>According to Jo, moving from shape P to shape ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Neither is correct</td>\n",
       "      <td>95</td>\n",
       "      <td>1868_D</td>\n",
       "      <td>True</td>\n",
       "      <td>Subject: Rotation. Construct: Describe a 90° o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15291</th>\n",
       "      <td>1868</td>\n",
       "      <td>2680</td>\n",
       "      <td>Describe a 90° or 270° rotation giving the ang...</td>\n",
       "      <td>93</td>\n",
       "      <td>Rotation</td>\n",
       "      <td>B</td>\n",
       "      <td>Only Paul</td>\n",
       "      <td>Paul argues that the transition from shape P t...</td>\n",
       "      <td>D</td>\n",
       "      <td>Neither is correct</td>\n",
       "      <td>95</td>\n",
       "      <td>1868_D</td>\n",
       "      <td>True</td>\n",
       "      <td>Subject: Rotation. Construct: Describe a 90° o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15292</th>\n",
       "      <td>1868</td>\n",
       "      <td>2680</td>\n",
       "      <td>Describe a 90° or 270° rotation giving the ang...</td>\n",
       "      <td>93</td>\n",
       "      <td>Rotation</td>\n",
       "      <td>B</td>\n",
       "      <td>Only Paul</td>\n",
       "      <td>Paul asserts that to rotate from shape P to sh...</td>\n",
       "      <td>D</td>\n",
       "      <td>Neither is correct</td>\n",
       "      <td>95</td>\n",
       "      <td>1868_D</td>\n",
       "      <td>True</td>\n",
       "      <td>Subject: Rotation. Construct: Describe a 90° o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15293 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       QuestionId  ConstructId  \\\n",
       "0               0          856   \n",
       "1               0          856   \n",
       "2               0          856   \n",
       "3               0          856   \n",
       "4               0          856   \n",
       "...           ...          ...   \n",
       "15288        1868         2680   \n",
       "15289        1868         2680   \n",
       "15290        1868         2680   \n",
       "15291        1868         2680   \n",
       "15292        1868         2680   \n",
       "\n",
       "                                           ConstructName  SubjectId  \\\n",
       "0      Use the order of operations to carry out calcu...         33   \n",
       "1      Use the order of operations to carry out calcu...         33   \n",
       "2      Use the order of operations to carry out calcu...         33   \n",
       "3      Use the order of operations to carry out calcu...         33   \n",
       "4      Use the order of operations to carry out calcu...         33   \n",
       "...                                                  ...        ...   \n",
       "15288  Describe a 90° or 270° rotation giving the ang...         93   \n",
       "15289  Describe a 90° or 270° rotation giving the ang...         93   \n",
       "15290  Describe a 90° or 270° rotation giving the ang...         93   \n",
       "15291  Describe a 90° or 270° rotation giving the ang...         93   \n",
       "15292  Describe a 90° or 270° rotation giving the ang...         93   \n",
       "\n",
       "      SubjectName CorrectChoice            CorrectText  \\\n",
       "0          BIDMAS             A  \\( 3 \\times(2+4)-5 \\)   \n",
       "1          BIDMAS             A  \\( 3 \\times(2+4)-5 \\)   \n",
       "2          BIDMAS             A  \\( 3 \\times(2+4)-5 \\)   \n",
       "3          BIDMAS             A  \\( 3 \\times(2+4)-5 \\)   \n",
       "4          BIDMAS             A  \\( 3 \\times(2+4)-5 \\)   \n",
       "...           ...           ...                    ...   \n",
       "15288    Rotation             B              Only Paul   \n",
       "15289    Rotation             B              Only Paul   \n",
       "15290    Rotation             B              Only Paul   \n",
       "15291    Rotation             B              Only Paul   \n",
       "15292    Rotation             B              Only Paul   \n",
       "\n",
       "                                            QuestionText WrongChoice  \\\n",
       "0      \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...           D   \n",
       "1      What placement of brackets will result in the ...           D   \n",
       "2      In the equation 3 × 2 + 4 - 5, where should br...           D   \n",
       "3      How can brackets be arranged in the expression...           D   \n",
       "4      Which locations for brackets in the expression...           D   \n",
       "...                                                  ...         ...   \n",
       "15288  Jo and Paul are arguing about how to fully des...           D   \n",
       "15289  Jo claims that the rotation from shape P to sh...           D   \n",
       "15290  According to Jo, moving from shape P to shape ...           D   \n",
       "15291  Paul argues that the transition from shape P t...           D   \n",
       "15292  Paul asserts that to rotate from shape P to sh...           D   \n",
       "\n",
       "                    WrongText  MisconceptionId QuestionId_Answer  \\\n",
       "0      Does not need brackets             1672               0_D   \n",
       "1      Does not need brackets             1672               0_D   \n",
       "2      Does not need brackets             1672               0_D   \n",
       "3      Does not need brackets             1672               0_D   \n",
       "4      Does not need brackets             1672               0_D   \n",
       "...                       ...              ...               ...   \n",
       "15288      Neither is correct               95            1868_D   \n",
       "15289      Neither is correct               95            1868_D   \n",
       "15290      Neither is correct               95            1868_D   \n",
       "15291      Neither is correct               95            1868_D   \n",
       "15292      Neither is correct               95            1868_D   \n",
       "\n",
       "       QuestionAiCreated                                   QuestionComplete  \n",
       "0                  False  Subject: BIDMAS. Construct: Use the order of o...  \n",
       "1                   True  Subject: BIDMAS. Construct: Use the order of o...  \n",
       "2                   True  Subject: BIDMAS. Construct: Use the order of o...  \n",
       "3                   True  Subject: BIDMAS. Construct: Use the order of o...  \n",
       "4                   True  Subject: BIDMAS. Construct: Use the order of o...  \n",
       "...                  ...                                                ...  \n",
       "15288              False  Subject: Rotation. Construct: Describe a 90° o...  \n",
       "15289               True  Subject: Rotation. Construct: Describe a 90° o...  \n",
       "15290               True  Subject: Rotation. Construct: Describe a 90° o...  \n",
       "15291               True  Subject: Rotation. Construct: Describe a 90° o...  \n",
       "15292               True  Subject: Rotation. Construct: Describe a 90° o...  \n",
       "\n",
       "[15293 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def batched_inference(model, tokenizer, texts: list[str], bs: int, desc: str) -> Tensor:\n",
    "    \"\"\"Basically SentenceTransformer.encode, but consume less vram.\"\"\"\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), bs), desc=desc):\n",
    "        # max_length=256 comes from plotting the complete question text, and 256 covers 99%\n",
    "        encoded = tokenizer(\n",
    "            texts[i : i + bs],\n",
    "            max_length=256,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(\"cuda\")\n",
    "        outputs = model(**encoded)\n",
    "        emb = outputs.last_hidden_state[:, 0]  # cls token\n",
    "        emb = F.normalize(emb, p=2, dim=-1)\n",
    "        embeddings.append(emb.cpu())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hn_mine_hf(\n",
    "#     model,\n",
    "#     tokenizer,\n",
    "#     q_texts: list[str],\n",
    "#     q_mis_ids: list[int],\n",
    "#     mis_texts: list[str],\n",
    "#     mis_ids: list[int],\n",
    "#     k: int,\n",
    "#     bs: int,\n",
    "# ) -> list[list[int]]:\n",
    "#     \"\"\"Hard negative mining, but different from: https://www.sbert.net/docs/package_reference/util.html#sentence_transformers.util.mine_hard_negatives.\n",
    "#     Sentence Transformers' version assumes different rows are always negatives, but that is not the case if we use paraphrased data.\n",
    "\n",
    "#     Args:\n",
    "#         q_texts (list[str]): Question texts.\n",
    "#         q_mis_ids (list[int]): Ground truth misconception ids for the questions.\n",
    "#         mis_texts (list[str]): Misconception texts.\n",
    "#         mis_ids (list[int]): Misconception ids.\n",
    "#         k (int): Top k hard misconception ids per question.\n",
    "#         bs (int): Batch size.\n",
    "\n",
    "#     Returns:\n",
    "#         list[list[int]]:\n",
    "#             Hard misconceptions for each question.\n",
    "#             This is NOT misconception ids, but the actual list index.\n",
    "#     \"\"\"\n",
    "#     assert len(q_texts) == len(q_mis_ids)\n",
    "#     assert len(mis_texts) == len(mis_ids)\n",
    "#     m_embeds = batched_inference(\n",
    "#         model, tokenizer, mis_texts, bs=bs, desc=\"miscon\"\n",
    "#     ).numpy()\n",
    "#     index = Index(ndim=m_embeds.shape[-1], metric=\"ip\")\n",
    "#     index.add(np.arange(m_embeds.shape[0]), m_embeds)\n",
    "#     q_embeds = batched_inference(\n",
    "#         model, tokenizer, q_texts, bs=bs, desc=\"questions\"\n",
    "#     ).numpy()\n",
    "#     batch_matches = index.search(q_embeds, count=k)\n",
    "#     hards = []\n",
    "#     for i, matches in enumerate(batch_matches):  # type: ignore\n",
    "#         nth_miscons: list[int] = [m.key for m in matches]\n",
    "#         hard_miscons = [nth for nth in nth_miscons if mis_ids[nth] != q_mis_ids[i]]\n",
    "#         hards.append(hard_miscons)\n",
    "#     assert len(hards) == len(q_texts)\n",
    "#     return hards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hn_mine_st(\n",
    "    model: SentenceTransformer,\n",
    "    q_texts: list[str],\n",
    "    q_mis_ids: list[int],\n",
    "    mis_texts: list[str],\n",
    "    mis_ids: list[int],\n",
    "    k: int,\n",
    "    bs: int,\n",
    ") -> list[list[int]]:\n",
    "    \"\"\"Hard negative mining, but different from: https://www.sbert.net/docs/package_reference/util.html#sentence_transformers.util.mine_hard_negatives.\n",
    "    Sentence Transformers' version assumes different rows are always negatives, but that is not the case if we use paraphrased data.\n",
    "\n",
    "    Args:\n",
    "        q_texts (list[str]): Question texts.\n",
    "        q_mis_ids (list[int]): Ground truth misconception ids for the questions.\n",
    "        mis_texts (list[str]): Misconception texts.\n",
    "        mis_ids (list[int]): Misconception ids.\n",
    "        k (int): Top k hard misconception ids per question (at max).\n",
    "        bs (int): Batch size.\n",
    "\n",
    "    Returns:\n",
    "        list[list[int]]:\n",
    "            Hard misconceptions for each question.\n",
    "            This is NOT misconception ids, but the actual list index.\n",
    "    \"\"\"\n",
    "    assert len(q_texts) == len(q_mis_ids)\n",
    "    assert len(mis_texts) == len(mis_ids)\n",
    "    m_embeds = model.encode(\n",
    "        mis_texts,\n",
    "        batch_size=bs,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=True,\n",
    "        device=\"cuda\",\n",
    "    )\n",
    "    index = Index(ndim=m_embeds.shape[-1], metric=\"ip\")\n",
    "    index.add(np.arange(m_embeds.shape[0]), m_embeds)\n",
    "    q_embeds = model.encode(\n",
    "        q_texts,\n",
    "        batch_size=bs,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=True,\n",
    "        device=\"cuda\",\n",
    "    )\n",
    "    batch_matches = index.search(q_embeds, count=k)\n",
    "    hards = []\n",
    "    for i, matches in enumerate(batch_matches):  # type: ignore\n",
    "        nth_miscons = [m.key for m in matches]\n",
    "        hard_miscons = [\n",
    "            nth.item() for nth in nth_miscons if mis_ids[nth] != q_mis_ids[i]\n",
    "        ]\n",
    "        hards.append(hard_miscons)\n",
    "    assert len(hards) == len(q_texts)\n",
    "    return hards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hards = hn_mine_hf(\n",
    "#     model_,\n",
    "#     tokenizer_,\n",
    "#     q_texts=df_q[\"QuestionComplete\"].tolist(),\n",
    "#     q_mis_ids=df_q[\"MisconceptionId\"].tolist(),\n",
    "#     mis_texts=df_m[\"MisconceptionText\"].tolist(),\n",
    "#     mis_ids=df_m[\"MisconceptionId\"].tolist(),\n",
    "#     k=100,\n",
    "#     bs=16,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from cache\n"
     ]
    }
   ],
   "source": [
    "cache = Path(\"hards.json\")\n",
    "if cache.exists():\n",
    "    print(\"loading from cache\")\n",
    "    with open(cache, \"r\") as f:\n",
    "        hards_st = json.load(f)\n",
    "else:\n",
    "    print(\"no cache, precomputing\")\n",
    "    hards_st = hn_mine_st(\n",
    "        model,\n",
    "        q_texts=df_train[\"QuestionComplete\"].tolist(),\n",
    "        q_mis_ids=df_train[\"MisconceptionId\"].tolist(),\n",
    "        mis_texts=df_mis[\"MisconceptionText\"].tolist(),\n",
    "        mis_ids=df_mis[\"MisconceptionId\"].tolist(),\n",
    "        k=100,\n",
    "        bs=4,\n",
    "    )\n",
    "    with open(cache, \"w\") as f:\n",
    "        json.dump(hards_st, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['q', 'mis', 'neg_1', 'neg_2', 'neg_3', 'neg_4', 'neg_5', 'neg_6', 'neg_7', 'neg_8', 'neg_9', 'neg_10'],\n",
       "    num_rows: 15293\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_mnr_dataset(\n",
    "    q_texts: list[str],\n",
    "    q_mis_ids: list[int],\n",
    "    mis_texts: list[str],\n",
    "    mis_ids: list[int],\n",
    "    hards: list[list[int]],\n",
    "    n_negatives: int,\n",
    ") -> HFDataset:\n",
    "    \"\"\"Create SentenceTransformer dataset suitable for MultipleNegativesRankingLoss.\n",
    "    The format is (anchor, positive, negative_1, …, negative_n).\n",
    "    Example: https://huggingface.co/datasets/tomaarsen/gooaq-hard-negatives\n",
    "    \"\"\"\n",
    "    assert len(q_texts) == len(q_mis_ids) == len(hards)\n",
    "    assert len(mis_texts) == len(mis_ids)\n",
    "    assert all(n_negatives <= len(hard) for hard in hards)\n",
    "    # create reverse mapping\n",
    "    mis_id_to_mis_idx = defaultdict(list)\n",
    "    for i, mis_id in enumerate(mis_ids):\n",
    "        mis_id_to_mis_idx[mis_id].append(i)\n",
    "    # make hf dataset\n",
    "    d = {}\n",
    "    d[\"q\"], d[\"mis\"] = [], []\n",
    "    for i in range(1, n_negatives + 1):\n",
    "        d[f\"neg_{i}\"] = []\n",
    "    for i, (q_text, q_mis_id) in enumerate(zip(q_texts, q_mis_ids)):\n",
    "        rand_pos = random.choice(mis_id_to_mis_idx[q_mis_id])\n",
    "        rand_negs = random.sample(hards[i], k=n_negatives)\n",
    "        d[\"q\"].append(q_text)\n",
    "        d[\"mis\"].append(mis_texts[rand_pos])\n",
    "        for j, rand_neg in enumerate(rand_negs, 1):\n",
    "            d[f\"neg_{j}\"].append(mis_texts[rand_neg])\n",
    "    return HFDataset.from_dict(d)\n",
    "\n",
    "\n",
    "ds = make_mnr_dataset(\n",
    "    q_texts=df_train[\"QuestionComplete\"].tolist(),\n",
    "    q_mis_ids=df_train[\"MisconceptionId\"].tolist(),\n",
    "    mis_texts=df_mis[\"MisconceptionText\"].tolist(),\n",
    "    mis_ids=df_mis[\"MisconceptionId\"].tolist(),\n",
    "    hards=hards_st,\n",
    "    n_negatives=10,\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HFDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['q', 'mis', 'label'],\n",
       "    num_rows: 168223\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_cosent_dataset(\n",
    "    q_texts: list[str],\n",
    "    q_mis_ids: list[int],\n",
    "    mis_texts: list[str],\n",
    "    mis_ids: list[int],\n",
    "    hards: list[list[int]],\n",
    "    n_negatives: int,\n",
    ") -> HFDataset:\n",
    "    \"\"\"Create SentenceTransformer dataset suitable for CoSENTLoss.\n",
    "    The format is (sentence_A, sentence_B).\n",
    "    Example: https://sbert.net/docs/sentence_transformer/training_overview.html#loss-function\n",
    "    \"\"\"\n",
    "    assert len(q_texts) == len(q_mis_ids) == len(hards)\n",
    "    assert len(mis_texts) == len(mis_ids)\n",
    "    assert all(n_negatives <= len(hard) for hard in hards)\n",
    "    # create reverse mapping\n",
    "    mis_id_to_mis_idx = defaultdict(list)\n",
    "    for i, mis_id in enumerate(mis_ids):\n",
    "        mis_id_to_mis_idx[mis_id].append(i)\n",
    "    # make hf dataset\n",
    "    d = {\"q\": [], \"mis\": [], \"label\": []}\n",
    "    for i, (q_text, q_mis_id) in enumerate(zip(q_texts, q_mis_ids)):\n",
    "        # insert positive\n",
    "        rand_pos = random.choice(mis_id_to_mis_idx[q_mis_id])\n",
    "        d[\"q\"].append(q_text)\n",
    "        d[\"mis\"].append(mis_texts[rand_pos])\n",
    "        d[\"label\"].append(1.0)\n",
    "        # insert negatives\n",
    "        rand_negs = random.sample(hards[i], k=n_negatives)\n",
    "        for j, rand_neg in enumerate(rand_negs, 1):\n",
    "            d[\"q\"].append(q_text)\n",
    "            d[\"mis\"].append(mis_texts[rand_neg])\n",
    "            d[\"label\"].append(-1.0)\n",
    "    return HFDataset.from_dict(d)\n",
    "\n",
    "\n",
    "ds2 = make_cosent_dataset(\n",
    "    q_texts=df_train[\"QuestionComplete\"].tolist(),\n",
    "    q_mis_ids=df_train[\"MisconceptionId\"].tolist(),\n",
    "    mis_texts=df_mis[\"MisconceptionText\"].tolist(),\n",
    "    mis_ids=df_mis[\"MisconceptionId\"].tolist(),\n",
    "    hards=hards_st,\n",
    "    n_negatives=10,\n",
    ")\n",
    "ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>ConstructId</th>\n",
       "      <th>ConstructName</th>\n",
       "      <th>SubjectId</th>\n",
       "      <th>SubjectName</th>\n",
       "      <th>CorrectChoice</th>\n",
       "      <th>CorrectText</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>WrongChoice</th>\n",
       "      <th>WrongText</th>\n",
       "      <th>MisconceptionId</th>\n",
       "      <th>QuestionId_Answer</th>\n",
       "      <th>QuestionAiCreated</th>\n",
       "      <th>QuestionComplete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>2578</td>\n",
       "      <td>Calculate the area of an equilateral triangle ...</td>\n",
       "      <td>75</td>\n",
       "      <td>Area of Simple Shapes</td>\n",
       "      <td>D</td>\n",
       "      <td>None of these</td>\n",
       "      <td>How would you calculate the area of this trian...</td>\n",
       "      <td>B</td>\n",
       "      <td>\\( \\frac{12 \\times 12}{2} \\)</td>\n",
       "      <td>590</td>\n",
       "      <td>15_B</td>\n",
       "      <td>False</td>\n",
       "      <td>Subject: Area of Simple Shapes. Construct: Cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>2578</td>\n",
       "      <td>Calculate the area of an equilateral triangle ...</td>\n",
       "      <td>75</td>\n",
       "      <td>Area of Simple Shapes</td>\n",
       "      <td>D</td>\n",
       "      <td>None of these</td>\n",
       "      <td>How would you calculate the area of this trian...</td>\n",
       "      <td>C</td>\n",
       "      <td>\\( \\frac{12 \\times 12 \\times 12}{2} \\)</td>\n",
       "      <td>71</td>\n",
       "      <td>15_C</td>\n",
       "      <td>False</td>\n",
       "      <td>Subject: Area of Simple Shapes. Construct: Cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>2742</td>\n",
       "      <td>Interpret sloping linear sections of a displac...</td>\n",
       "      <td>58</td>\n",
       "      <td>Real Life Graphs</td>\n",
       "      <td>A</td>\n",
       "      <td>Fido is walking home</td>\n",
       "      <td>This graph shows how far Fido the dog is from ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Fido has fallen asleep</td>\n",
       "      <td>2492</td>\n",
       "      <td>23_B</td>\n",
       "      <td>False</td>\n",
       "      <td>Subject: Real Life Graphs. Construct: Interpre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>2742</td>\n",
       "      <td>Interpret sloping linear sections of a displac...</td>\n",
       "      <td>58</td>\n",
       "      <td>Real Life Graphs</td>\n",
       "      <td>A</td>\n",
       "      <td>Fido is walking home</td>\n",
       "      <td>This graph shows how far Fido the dog is from ...</td>\n",
       "      <td>C</td>\n",
       "      <td>Fido is accelerating</td>\n",
       "      <td>2032</td>\n",
       "      <td>23_C</td>\n",
       "      <td>False</td>\n",
       "      <td>Subject: Real Life Graphs. Construct: Interpre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>2742</td>\n",
       "      <td>Interpret sloping linear sections of a displac...</td>\n",
       "      <td>58</td>\n",
       "      <td>Real Life Graphs</td>\n",
       "      <td>A</td>\n",
       "      <td>Fido is walking home</td>\n",
       "      <td>This graph shows how far Fido the dog is from ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Fido is walking away from home</td>\n",
       "      <td>2437</td>\n",
       "      <td>23_D</td>\n",
       "      <td>False</td>\n",
       "      <td>Subject: Real Life Graphs. Construct: Interpre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1859</td>\n",
       "      <td>2741</td>\n",
       "      <td>Read values off a displacement-time graph</td>\n",
       "      <td>117</td>\n",
       "      <td>Time Series and Line Graphs</td>\n",
       "      <td>C</td>\n",
       "      <td>\\( 1.5 \\ \\text{m} \\)</td>\n",
       "      <td>This graph shows the displacement of a ball fr...</td>\n",
       "      <td>B</td>\n",
       "      <td>\\( 2 \\ \\text{m} \\)</td>\n",
       "      <td>378</td>\n",
       "      <td>1859_B</td>\n",
       "      <td>False</td>\n",
       "      <td>Subject: Time Series and Line Graphs. Construc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1859</td>\n",
       "      <td>2741</td>\n",
       "      <td>Read values off a displacement-time graph</td>\n",
       "      <td>117</td>\n",
       "      <td>Time Series and Line Graphs</td>\n",
       "      <td>C</td>\n",
       "      <td>\\( 1.5 \\ \\text{m} \\)</td>\n",
       "      <td>This graph shows the displacement of a ball fr...</td>\n",
       "      <td>D</td>\n",
       "      <td>\\( 2.5 \\ \\text{m} \\)</td>\n",
       "      <td>1887</td>\n",
       "      <td>1859_D</td>\n",
       "      <td>False</td>\n",
       "      <td>Subject: Time Series and Line Graphs. Construc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>1864</td>\n",
       "      <td>2774</td>\n",
       "      <td>Calculate the range from a list of data</td>\n",
       "      <td>339</td>\n",
       "      <td>Range and Interquartile Range from a List of Data</td>\n",
       "      <td>C</td>\n",
       "      <td>\\( 23 \\)</td>\n",
       "      <td>What is the range of the following numbers?\\n\\...</td>\n",
       "      <td>A</td>\n",
       "      <td>\\( 5 \\)</td>\n",
       "      <td>2456</td>\n",
       "      <td>1864_A</td>\n",
       "      <td>False</td>\n",
       "      <td>Subject: Range and Interquartile Range from a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1864</td>\n",
       "      <td>2774</td>\n",
       "      <td>Calculate the range from a list of data</td>\n",
       "      <td>339</td>\n",
       "      <td>Range and Interquartile Range from a List of Data</td>\n",
       "      <td>C</td>\n",
       "      <td>\\( 23 \\)</td>\n",
       "      <td>What is the range of the following numbers?\\n\\...</td>\n",
       "      <td>B</td>\n",
       "      <td>\\( 11 \\)</td>\n",
       "      <td>691</td>\n",
       "      <td>1864_B</td>\n",
       "      <td>False</td>\n",
       "      <td>Subject: Range and Interquartile Range from a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>1864</td>\n",
       "      <td>2774</td>\n",
       "      <td>Calculate the range from a list of data</td>\n",
       "      <td>339</td>\n",
       "      <td>Range and Interquartile Range from a List of Data</td>\n",
       "      <td>C</td>\n",
       "      <td>\\( 23 \\)</td>\n",
       "      <td>What is the range of the following numbers?\\n\\...</td>\n",
       "      <td>D</td>\n",
       "      <td>\\( 16 \\)</td>\n",
       "      <td>1349</td>\n",
       "      <td>1864_D</td>\n",
       "      <td>False</td>\n",
       "      <td>Subject: Range and Interquartile Range from a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      QuestionId  ConstructId  \\\n",
       "0             15         2578   \n",
       "1             15         2578   \n",
       "2             23         2742   \n",
       "3             23         2742   \n",
       "4             23         2742   \n",
       "...          ...          ...   \n",
       "1308        1859         2741   \n",
       "1309        1859         2741   \n",
       "1310        1864         2774   \n",
       "1311        1864         2774   \n",
       "1312        1864         2774   \n",
       "\n",
       "                                          ConstructName  SubjectId  \\\n",
       "0     Calculate the area of an equilateral triangle ...         75   \n",
       "1     Calculate the area of an equilateral triangle ...         75   \n",
       "2     Interpret sloping linear sections of a displac...         58   \n",
       "3     Interpret sloping linear sections of a displac...         58   \n",
       "4     Interpret sloping linear sections of a displac...         58   \n",
       "...                                                 ...        ...   \n",
       "1308          Read values off a displacement-time graph        117   \n",
       "1309          Read values off a displacement-time graph        117   \n",
       "1310            Calculate the range from a list of data        339   \n",
       "1311            Calculate the range from a list of data        339   \n",
       "1312            Calculate the range from a list of data        339   \n",
       "\n",
       "                                            SubjectName CorrectChoice  \\\n",
       "0                                 Area of Simple Shapes             D   \n",
       "1                                 Area of Simple Shapes             D   \n",
       "2                                      Real Life Graphs             A   \n",
       "3                                      Real Life Graphs             A   \n",
       "4                                      Real Life Graphs             A   \n",
       "...                                                 ...           ...   \n",
       "1308                        Time Series and Line Graphs             C   \n",
       "1309                        Time Series and Line Graphs             C   \n",
       "1310  Range and Interquartile Range from a List of Data             C   \n",
       "1311  Range and Interquartile Range from a List of Data             C   \n",
       "1312  Range and Interquartile Range from a List of Data             C   \n",
       "\n",
       "               CorrectText                                       QuestionText  \\\n",
       "0            None of these  How would you calculate the area of this trian...   \n",
       "1            None of these  How would you calculate the area of this trian...   \n",
       "2     Fido is walking home  This graph shows how far Fido the dog is from ...   \n",
       "3     Fido is walking home  This graph shows how far Fido the dog is from ...   \n",
       "4     Fido is walking home  This graph shows how far Fido the dog is from ...   \n",
       "...                    ...                                                ...   \n",
       "1308  \\( 1.5 \\ \\text{m} \\)  This graph shows the displacement of a ball fr...   \n",
       "1309  \\( 1.5 \\ \\text{m} \\)  This graph shows the displacement of a ball fr...   \n",
       "1310              \\( 23 \\)  What is the range of the following numbers?\\n\\...   \n",
       "1311              \\( 23 \\)  What is the range of the following numbers?\\n\\...   \n",
       "1312              \\( 23 \\)  What is the range of the following numbers?\\n\\...   \n",
       "\n",
       "     WrongChoice                               WrongText  MisconceptionId  \\\n",
       "0              B            \\( \\frac{12 \\times 12}{2} \\)              590   \n",
       "1              C  \\( \\frac{12 \\times 12 \\times 12}{2} \\)               71   \n",
       "2              B                  Fido has fallen asleep             2492   \n",
       "3              C                    Fido is accelerating             2032   \n",
       "4              D          Fido is walking away from home             2437   \n",
       "...          ...                                     ...              ...   \n",
       "1308           B                      \\( 2 \\ \\text{m} \\)              378   \n",
       "1309           D                    \\( 2.5 \\ \\text{m} \\)             1887   \n",
       "1310           A                                 \\( 5 \\)             2456   \n",
       "1311           B                                \\( 11 \\)              691   \n",
       "1312           D                                \\( 16 \\)             1349   \n",
       "\n",
       "     QuestionId_Answer  QuestionAiCreated  \\\n",
       "0                 15_B              False   \n",
       "1                 15_C              False   \n",
       "2                 23_B              False   \n",
       "3                 23_C              False   \n",
       "4                 23_D              False   \n",
       "...                ...                ...   \n",
       "1308            1859_B              False   \n",
       "1309            1859_D              False   \n",
       "1310            1864_A              False   \n",
       "1311            1864_B              False   \n",
       "1312            1864_D              False   \n",
       "\n",
       "                                       QuestionComplete  \n",
       "0     Subject: Area of Simple Shapes. Construct: Cal...  \n",
       "1     Subject: Area of Simple Shapes. Construct: Cal...  \n",
       "2     Subject: Real Life Graphs. Construct: Interpre...  \n",
       "3     Subject: Real Life Graphs. Construct: Interpre...  \n",
       "4     Subject: Real Life Graphs. Construct: Interpre...  \n",
       "...                                                 ...  \n",
       "1308  Subject: Time Series and Line Graphs. Construc...  \n",
       "1309  Subject: Time Series and Line Graphs. Construc...  \n",
       "1310  Subject: Range and Interquartile Range from a ...  \n",
       "1311  Subject: Range and Interquartile Range from a ...  \n",
       "1312  Subject: Range and Interquartile Range from a ...  \n",
       "\n",
       "[1313 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ir_evaluator_dataset(\n",
    "    df_val: pd.DataFrame, orig_mis: list[str]\n",
    ") -> tuple[dict, dict, dict]:\n",
    "    assert len(orig_mis) == 2587\n",
    "    mapping = (\n",
    "        df_val[[\"QuestionId_Answer\", \"MisconceptionId\"]]\n",
    "        .set_index(\"QuestionId_Answer\")[\"MisconceptionId\"]\n",
    "        .apply(lambda x: [x])\n",
    "        .to_dict()\n",
    "    )\n",
    "    q = (\n",
    "        df_val[[\"QuestionId_Answer\", \"QuestionComplete\"]]\n",
    "        .set_index(\"QuestionId_Answer\")[\"QuestionComplete\"]\n",
    "        .to_dict()\n",
    "    )\n",
    "    mis = {i: mis_text for i, mis_text in enumerate(orig_mis)}\n",
    "    return q, mis, mapping\n",
    "\n",
    "\n",
    "q, mis, mapping = make_ir_evaluator_dataset(df_val, orig_mis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a602541d987409abc030f15c82975d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:14<00:00, 14.39s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluator = InformationRetrievalEvaluator(\n",
    "    queries=q,\n",
    "    corpus=mis,\n",
    "    relevant_docs=mapping,\n",
    "    map_at_k=[1, 3, 5, 10, 25],\n",
    "    batch_size=4,\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "results = evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cosine_accuracy@1': 0.07006854531607007,\n",
       " 'cosine_accuracy@3': 0.1728865194211729,\n",
       " 'cosine_accuracy@5': 0.24523990860624523,\n",
       " 'cosine_accuracy@10': 0.361005331302361,\n",
       " 'cosine_precision@1': 0.07006854531607007,\n",
       " 'cosine_precision@3': 0.05762883980705762,\n",
       " 'cosine_precision@5': 0.04904798172124905,\n",
       " 'cosine_precision@10': 0.036100533130236104,\n",
       " 'cosine_recall@1': 0.07006854531607007,\n",
       " 'cosine_recall@3': 0.1728865194211729,\n",
       " 'cosine_recall@5': 0.24523990860624523,\n",
       " 'cosine_recall@10': 0.361005331302361,\n",
       " 'cosine_ndcg@10': 0.19553563097479792,\n",
       " 'cosine_mrr@10': 0.14515588921529496,\n",
       " 'cosine_map@1': 0.07006854531607007,\n",
       " 'cosine_map@3': 0.11398832190911398,\n",
       " 'cosine_map@5': 0.13005839045443005,\n",
       " 'cosine_map@10': 0.14515588921529515,\n",
       " 'cosine_map@25': 0.1540876920346375,\n",
       " 'dot_accuracy@1': 0.07083015993907082,\n",
       " 'dot_accuracy@3': 0.1782178217821782,\n",
       " 'dot_accuracy@5': 0.2421934501142422,\n",
       " 'dot_accuracy@10': 0.3602437166793602,\n",
       " 'dot_precision@1': 0.07083015993907082,\n",
       " 'dot_precision@3': 0.0594059405940594,\n",
       " 'dot_precision@5': 0.04843869002284844,\n",
       " 'dot_precision@10': 0.036024371667936025,\n",
       " 'dot_recall@1': 0.07083015993907082,\n",
       " 'dot_recall@3': 0.1782178217821782,\n",
       " 'dot_recall@5': 0.2421934501142422,\n",
       " 'dot_recall@10': 0.3602437166793602,\n",
       " 'dot_ndcg@10': 0.19759664717151854,\n",
       " 'dot_mrr@10': 0.14790918652304777,\n",
       " 'dot_map@1': 0.07083015993907082,\n",
       " 'dot_map@3': 0.11779639502411779,\n",
       " 'dot_map@5': 0.13222899212998224,\n",
       " 'dot_map@10': 0.14790918652304788,\n",
       " 'dot_map@25': 0.15751345921931273}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw training, move this to script, and make cached hn mining because we will hammer the script a LOT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mevanarlian\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/evan/Documents/kaggle/kaggle-eedi/wandb/run-20241123_160520-wkqyoqq7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/evanarlian/sentence-transformers/runs/wkqyoqq7' target=\"_blank\">gte-large-en-1-wandb</a></strong> to <a href='https://wandb.ai/evanarlian/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/evanarlian/sentence-transformers' target=\"_blank\">https://wandb.ai/evanarlian/sentence-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/evanarlian/sentence-transformers/runs/wkqyoqq7' target=\"_blank\">https://wandb.ai/evanarlian/sentence-transformers/runs/wkqyoqq7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6073a1796c1440fdad9d4077c4ed338b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 11.64 GiB of which 28.81 MiB is free. Including non-PyTorch memory, this process has 10.63 GiB memory in use. Of the allocated memory 10.44 GiB is allocated by PyTorch, and 59.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 46\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# 7. Create a trainer & train\u001b[39;00m\n\u001b[1;32m     38\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SentenceTransformerTrainer(\n\u001b[1;32m     39\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     40\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39mevaluator,\n\u001b[1;32m     45\u001b[0m )\n\u001b[0;32m---> 46\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m evaluator(model)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# 8. Save the trained model\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/transformers/trainer.py:2388\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/transformers/trainer.py:3485\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3485\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3490\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3491\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/sentence_transformers/trainer.py:344\u001b[0m, in \u001b[0;36mSentenceTransformerTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    338\u001b[0m     model \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m model \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel  \u001b[38;5;66;03m# Only if the model is wrapped\u001b[39;00m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(loss_fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Only if the loss stores the model\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m loss_fn\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m model  \u001b[38;5;66;03m# Only if the wrapped model is not already stored\u001b[39;00m\n\u001b[1;32m    342\u001b[0m ):\n\u001b[1;32m    343\u001b[0m     loss_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverride_model_in_loss(loss_fn, model)\n\u001b[0;32m--> 344\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_outputs:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;66;03m# During prediction/evaluation, `compute_loss` will be called with `return_outputs=True`.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;66;03m# However, Sentence Transformer losses do not return outputs, so we return an empty dictionary.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;66;03m# This does not result in any problems, as the SentenceTransformerTrainingArguments sets\u001b[39;00m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# `prediction_loss_only=True` which means that the output is not used.\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss, {}\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py:101\u001b[0m, in \u001b[0;36mMultipleNegativesRankingLoss.forward\u001b[0;34m(self, sentence_features, labels)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence_features: Iterable[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor]], labels: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 101\u001b[0m     reps \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_feature\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentence_embedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence_feature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence_features\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    102\u001b[0m     embeddings_a \u001b[38;5;241m=\u001b[39m reps[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    103\u001b[0m     embeddings_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(reps[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py:101\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence_features: Iterable[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor]], labels: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 101\u001b[0m     reps \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_feature\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sentence_feature \u001b[38;5;129;01min\u001b[39;00m sentence_features]\n\u001b[1;32m    102\u001b[0m     embeddings_a \u001b[38;5;241m=\u001b[39m reps[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    103\u001b[0m     embeddings_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(reps[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/accelerate/utils/operations.py:820\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/accelerate/utils/operations.py:808\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/amp/autocast_mode.py:43\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:688\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    686\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[1;32m    687\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:350\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    348\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 350\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    353\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Alibaba-NLP/new-impl/40ced75c3017eb27626c9d4ea981bde21a2662f4/modeling.py:940\u001b[0m, in \u001b[0;36mNewModel.forward\u001b[0;34m(self, input_ids, attention_mask, length, subset_indices, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, unpad_inputs)\u001b[0m\n\u001b[1;32m    930\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTODO: logn_attention_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    931\u001b[0m \u001b[38;5;66;03m#     # attention scale log_512(input_len)\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;66;03m#     attention_scale = attention_mask.sum(1).log() / torch.tensor(self.config.max_position_embeddings).log()\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m#     # inference-time logn scale need clip 1\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m#     attention_scale = None\u001b[39;00m\n\u001b[0;32m--> 940\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrope_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrope_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unpad_inputs \u001b[38;5;129;01mand\u001b[39;00m output_padded:\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Alibaba-NLP/new-impl/40ced75c3017eb27626c9d4ea981bde21a2662f4/modeling.py:749\u001b[0m, in \u001b[0;36mNewEncoder.forward\u001b[0;34m(self, hidden_states, attention_bias, rope_embeds, padding_inputs, attention_scale, subset_indices, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    738\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    739\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    740\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m         layer_head_mask,\n\u001b[1;32m    747\u001b[0m     )\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 749\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrope_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_subset_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Alibaba-NLP/new-impl/40ced75c3017eb27626c9d4ea981bde21a2662f4/modeling.py:692\u001b[0m, in \u001b[0;36mNewLayer.forward\u001b[0;34m(self, hidden_states, attention_bias, rope_embeds, padding_inputs, attention_scale, subset_indices, head_mask, output_attentions, qkv_inputs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n\u001b[1;32m    691\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 692\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dropout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dropout(hidden_states)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Alibaba-NLP/new-impl/40ced75c3017eb27626c9d4ea981bde21a2662f4/modeling.py:619\u001b[0m, in \u001b[0;36mNewGatedMLP.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    617\u001b[0m gated_states \u001b[38;5;241m=\u001b[39m gate \u001b[38;5;241m*\u001b[39m up_states\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dropout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m     gated_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_dropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgated_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m down_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(gated_states)\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m down_states\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_eedi/lib/python3.11/site-packages/torch/nn/functional.py:1295\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 11.64 GiB of which 28.81 MiB is free. Including non-PyTorch memory, this process has 10.63 GiB memory in use. Of the allocated memory 10.44 GiB is allocated by PyTorch, and 59.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. Load a model to finetune with 2. (Optional) model card data (i skip it)\n",
    "model\n",
    "\n",
    "\n",
    "# 3. Load a dataset to finetune on\n",
    "ds\n",
    "\n",
    "# 4. Define a loss function\n",
    "loss = MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# 5. (Optional) Specify training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"models/gte-large-en-1-outdir\",  # TODO what is the difference vs save pretrained?\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    run_name=\"gte-large-en-1-wandb\",  # Will be used in W&B if `wandb` is installed\n",
    ")\n",
    "\n",
    "# 6. (Optional) Create an evaluator & evaluate the base model\n",
    "evaluator\n",
    "\n",
    "# 7. Create a trainer & train\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds2,\n",
    "    # eval_dataset=eval_dataset, # dont need eval dataset for now\n",
    "    loss=loss,\n",
    "    evaluator=evaluator,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "evaluator(model)\n",
    "\n",
    "# 8. Save the trained model\n",
    "model.save_pretrained(\"models/gte-large-en-1-local\")\n",
    "\n",
    "# 9. (Optional) Push it to the Hugging Face Hub\n",
    "model.push_to_hub(\"gte-large-en-1-hfpush\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ef95dc8bb2401799b193a280c7cdc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0000.parquet:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12d971b45d7401987373ebe913c1f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0001.parquet:   0%|          | 0.00/95.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03013e47f3c140929290c9dc79b056eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating corpus split:   0%|          | 0/382545 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb0b1a5d817431688efc276b6c736d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "queries/queries/0000.parquet:   0%|          | 0.00/3.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f0e495d080449b97b02af6ac04a977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating queries split:   0%|          | 0/49 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fdb538b9d34fc987aed42a4fc471ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/14.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c33001033734aeb86145e363eaf97b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.tsv:   0%|          | 0.00/101k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14da0569c607434e82711a4bc004a179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2214 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de62a2c08594acebd4ca668369e2c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/382545 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9cecca6bc748e6936b35f8938dbe06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/382545 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BeIR-touche2020-subset-test_cosine_map@100\n",
      "0.30561077016600136\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load a model\n",
    "modelmini = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Load the Touche-2020 IR dataset (https://huggingface.co/datasets/BeIR/webis-touche2020, https://huggingface.co/datasets/BeIR/webis-touche2020-qrels)\n",
    "corpus = load_dataset(\"BeIR/webis-touche2020\", \"corpus\", split=\"corpus\")\n",
    "queries = load_dataset(\"BeIR/webis-touche2020\", \"queries\", split=\"queries\")\n",
    "relevant_docs_data = load_dataset(\"BeIR/webis-touche2020-qrels\", split=\"test\")\n",
    "\n",
    "# For this dataset, we want to concatenate the title and texts for the corpus\n",
    "corpus = corpus.map(lambda x: {'text': x['title'] + \" \" + x['text']}, remove_columns=['title'])\n",
    "\n",
    "# Shrink the corpus size heavily to only the relevant documents + 30,000 random documents\n",
    "required_corpus_ids = set(map(str, relevant_docs_data[\"corpus-id\"]))\n",
    "required_corpus_ids |= set(random.sample(corpus[\"_id\"], k=30_000))\n",
    "corpus = corpus.filter(lambda x: x[\"_id\"] in required_corpus_ids)\n",
    "\n",
    "# Convert the datasets to dictionaries\n",
    "corpus = dict(zip(corpus[\"_id\"], corpus[\"text\"]))  # Our corpus (cid => document)\n",
    "queries = dict(zip(queries[\"_id\"], queries[\"text\"]))  # Our queries (qid => question)\n",
    "relevant_docs = {}  # Query ID to relevant documents (qid => set([relevant_cids])\n",
    "for qid, corpus_ids in zip(relevant_docs_data[\"query-id\"], relevant_docs_data[\"corpus-id\"]):\n",
    "    qid = str(qid)\n",
    "    corpus_ids = str(corpus_ids)\n",
    "    if qid not in relevant_docs:\n",
    "        relevant_docs[qid] = set()\n",
    "    relevant_docs[qid].add(corpus_ids)\n",
    "\n",
    "# Given queries, a corpus and a mapping with relevant documents, the InformationRetrievalEvaluator computes different IR metrics.\n",
    "ir_evaluator = InformationRetrievalEvaluator(\n",
    "    queries=queries,\n",
    "    corpus=corpus,\n",
    "    relevant_docs=relevant_docs,\n",
    "    name=\"BeIR-touche2020-subset-test\",\n",
    ")\n",
    "results = ir_evaluator(modelmini)\n",
    "'''\n",
    "Information Retrieval Evaluation of the model on the BeIR-touche2020-test dataset:\n",
    "Queries: 49\n",
    "Corpus: 31923\n",
    "\n",
    "Score-Function: cosine\n",
    "Accuracy@1: 77.55%\n",
    "Accuracy@3: 93.88%\n",
    "Accuracy@5: 97.96%\n",
    "Accuracy@10: 100.00%\n",
    "Precision@1: 77.55%\n",
    "Precision@3: 72.11%\n",
    "Precision@5: 71.43%\n",
    "Precision@10: 62.65%\n",
    "Recall@1: 1.72%\n",
    "Recall@3: 4.78%\n",
    "Recall@5: 7.90%\n",
    "Recall@10: 13.86%\n",
    "MRR@10: 0.8580\n",
    "NDCG@10: 0.6606\n",
    "MAP@100: 0.2934\n",
    "'''\n",
    "print(ir_evaluator.primary_metric)\n",
    "# => \"BeIR-touche2020-test_cosine_map@100\"\n",
    "print(results[ir_evaluator.primary_metric])\n",
    "# => 0.29335196224364596"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO this shit is taking so much time lol\n",
    "# * the minconception must come from ALL dataset\n",
    "# * but the\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2cfe56d1b0a479fa5daec57ca629f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "results = evaluator(modelmini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_eedi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
