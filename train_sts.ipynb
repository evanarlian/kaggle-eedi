{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sentence_transformers.losses import CoSENTLoss, MultipleNegativesRankingLoss\n",
    "from datasets import Dataset as HFDataset\n",
    "from itertools import islice\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from usearch.index import Index\n",
    "import string\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "from datasets import load_dataset\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_name = \"Alibaba-NLP/gte-large-en-v1.5\"\n",
    "model = SentenceTransformer(model_name, trust_remote_code=True)\n",
    "model_ = AutoModel.from_pretrained(model_name, trust_remote_code=True).cuda()\n",
    "tokenizer_ = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load paraphrased misconception\n",
    "df_mis = pd.read_csv(\"data/eedi-paraphrased/misconception_mapping.csv\")\n",
    "orig_mis = (\n",
    "    df_mis[~df_mis[\"MisconceptionAiCreated\"]]\n",
    "    .sort_values(\"MisconceptionId\")[\"MisconceptionText\"]\n",
    "    .tolist()\n",
    ")\n",
    "assert len(orig_mis) == 2587\n",
    "\n",
    "# load paraphrased train\n",
    "df = pd.read_csv(\"data/eedi-paraphrased/train.csv\")\n",
    "df[\"QuestionComplete\"] = (\n",
    "    \"Subject: \"\n",
    "    + df[\"SubjectName\"]\n",
    "    + \". Construct: \"\n",
    "    + df[\"ConstructName\"]\n",
    "    + \". Question: \"\n",
    "    + df[\"QuestionText\"]\n",
    "    + \". Correct answer: \"\n",
    "    + df[\"CorrectText\"]\n",
    "    + \". Wrong answer: \"\n",
    "    + df[\"WrongText\"]\n",
    "    + \".\"\n",
    ")\n",
    "\n",
    "# split to train (w miscons) and val (w/o miscons)\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.7, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(df, groups=df[\"QuestionId\"]))\n",
    "df_train = df.iloc[train_idx].reset_index(drop=True)\n",
    "df_val = df.iloc[val_idx]\n",
    "df_val = df_val[~df_val[\"QuestionAiCreated\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>ConstructId</th>\n",
       "      <th>ConstructName</th>\n",
       "      <th>SubjectId</th>\n",
       "      <th>SubjectName</th>\n",
       "      <th>CorrectChoice</th>\n",
       "      <th>CorrectText</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>WrongChoice</th>\n",
       "      <th>WrongText</th>\n",
       "      <th>MisconceptionId</th>\n",
       "      <th>QuestionId_Answer</th>\n",
       "      <th>QuestionAiCreated</th>\n",
       "      <th>QuestionComplete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>Use the order of operations to carry out calcu...</td>\n",
       "      <td>33</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>A</td>\n",
       "      <td>\\( 3 \\times(2+4)-5 \\)</td>\n",
       "      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Does not need brackets</td>\n",
       "      <td>1672</td>\n",
       "      <td>0_D</td>\n",
       "      <td>False</td>\n",
       "      <td>Subject: BIDMAS. Construct: Use the order of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>Use the order of operations to carry out calcu...</td>\n",
       "      <td>33</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>A</td>\n",
       "      <td>\\( 3 \\times(2+4)-5 \\)</td>\n",
       "      <td>What placement of brackets will result in the ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Does not need brackets</td>\n",
       "      <td>1672</td>\n",
       "      <td>0_D</td>\n",
       "      <td>True</td>\n",
       "      <td>Subject: BIDMAS. Construct: Use the order of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>Use the order of operations to carry out calcu...</td>\n",
       "      <td>33</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>A</td>\n",
       "      <td>\\( 3 \\times(2+4)-5 \\)</td>\n",
       "      <td>In the equation 3 × 2 + 4 - 5, where should br...</td>\n",
       "      <td>D</td>\n",
       "      <td>Does not need brackets</td>\n",
       "      <td>1672</td>\n",
       "      <td>0_D</td>\n",
       "      <td>True</td>\n",
       "      <td>Subject: BIDMAS. Construct: Use the order of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>Use the order of operations to carry out calcu...</td>\n",
       "      <td>33</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>A</td>\n",
       "      <td>\\( 3 \\times(2+4)-5 \\)</td>\n",
       "      <td>How can brackets be arranged in the expression...</td>\n",
       "      <td>D</td>\n",
       "      <td>Does not need brackets</td>\n",
       "      <td>1672</td>\n",
       "      <td>0_D</td>\n",
       "      <td>True</td>\n",
       "      <td>Subject: BIDMAS. Construct: Use the order of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>Use the order of operations to carry out calcu...</td>\n",
       "      <td>33</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>A</td>\n",
       "      <td>\\( 3 \\times(2+4)-5 \\)</td>\n",
       "      <td>Which locations for brackets in the expression...</td>\n",
       "      <td>D</td>\n",
       "      <td>Does not need brackets</td>\n",
       "      <td>1672</td>\n",
       "      <td>0_D</td>\n",
       "      <td>True</td>\n",
       "      <td>Subject: BIDMAS. Construct: Use the order of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15288</th>\n",
       "      <td>1868</td>\n",
       "      <td>2680</td>\n",
       "      <td>Describe a 90° or 270° rotation giving the ang...</td>\n",
       "      <td>93</td>\n",
       "      <td>Rotation</td>\n",
       "      <td>B</td>\n",
       "      <td>Only Paul</td>\n",
       "      <td>Jo and Paul are arguing about how to fully des...</td>\n",
       "      <td>D</td>\n",
       "      <td>Neither is correct</td>\n",
       "      <td>95</td>\n",
       "      <td>1868_D</td>\n",
       "      <td>False</td>\n",
       "      <td>Subject: Rotation. Construct: Describe a 90° o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15289</th>\n",
       "      <td>1868</td>\n",
       "      <td>2680</td>\n",
       "      <td>Describe a 90° or 270° rotation giving the ang...</td>\n",
       "      <td>93</td>\n",
       "      <td>Rotation</td>\n",
       "      <td>B</td>\n",
       "      <td>Only Paul</td>\n",
       "      <td>Jo claims that the rotation from shape P to sh...</td>\n",
       "      <td>D</td>\n",
       "      <td>Neither is correct</td>\n",
       "      <td>95</td>\n",
       "      <td>1868_D</td>\n",
       "      <td>True</td>\n",
       "      <td>Subject: Rotation. Construct: Describe a 90° o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15290</th>\n",
       "      <td>1868</td>\n",
       "      <td>2680</td>\n",
       "      <td>Describe a 90° or 270° rotation giving the ang...</td>\n",
       "      <td>93</td>\n",
       "      <td>Rotation</td>\n",
       "      <td>B</td>\n",
       "      <td>Only Paul</td>\n",
       "      <td>According to Jo, moving from shape P to shape ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Neither is correct</td>\n",
       "      <td>95</td>\n",
       "      <td>1868_D</td>\n",
       "      <td>True</td>\n",
       "      <td>Subject: Rotation. Construct: Describe a 90° o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15291</th>\n",
       "      <td>1868</td>\n",
       "      <td>2680</td>\n",
       "      <td>Describe a 90° or 270° rotation giving the ang...</td>\n",
       "      <td>93</td>\n",
       "      <td>Rotation</td>\n",
       "      <td>B</td>\n",
       "      <td>Only Paul</td>\n",
       "      <td>Paul argues that the transition from shape P t...</td>\n",
       "      <td>D</td>\n",
       "      <td>Neither is correct</td>\n",
       "      <td>95</td>\n",
       "      <td>1868_D</td>\n",
       "      <td>True</td>\n",
       "      <td>Subject: Rotation. Construct: Describe a 90° o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15292</th>\n",
       "      <td>1868</td>\n",
       "      <td>2680</td>\n",
       "      <td>Describe a 90° or 270° rotation giving the ang...</td>\n",
       "      <td>93</td>\n",
       "      <td>Rotation</td>\n",
       "      <td>B</td>\n",
       "      <td>Only Paul</td>\n",
       "      <td>Paul asserts that to rotate from shape P to sh...</td>\n",
       "      <td>D</td>\n",
       "      <td>Neither is correct</td>\n",
       "      <td>95</td>\n",
       "      <td>1868_D</td>\n",
       "      <td>True</td>\n",
       "      <td>Subject: Rotation. Construct: Describe a 90° o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15293 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       QuestionId  ConstructId  \\\n",
       "0               0          856   \n",
       "1               0          856   \n",
       "2               0          856   \n",
       "3               0          856   \n",
       "4               0          856   \n",
       "...           ...          ...   \n",
       "15288        1868         2680   \n",
       "15289        1868         2680   \n",
       "15290        1868         2680   \n",
       "15291        1868         2680   \n",
       "15292        1868         2680   \n",
       "\n",
       "                                           ConstructName  SubjectId  \\\n",
       "0      Use the order of operations to carry out calcu...         33   \n",
       "1      Use the order of operations to carry out calcu...         33   \n",
       "2      Use the order of operations to carry out calcu...         33   \n",
       "3      Use the order of operations to carry out calcu...         33   \n",
       "4      Use the order of operations to carry out calcu...         33   \n",
       "...                                                  ...        ...   \n",
       "15288  Describe a 90° or 270° rotation giving the ang...         93   \n",
       "15289  Describe a 90° or 270° rotation giving the ang...         93   \n",
       "15290  Describe a 90° or 270° rotation giving the ang...         93   \n",
       "15291  Describe a 90° or 270° rotation giving the ang...         93   \n",
       "15292  Describe a 90° or 270° rotation giving the ang...         93   \n",
       "\n",
       "      SubjectName CorrectChoice            CorrectText  \\\n",
       "0          BIDMAS             A  \\( 3 \\times(2+4)-5 \\)   \n",
       "1          BIDMAS             A  \\( 3 \\times(2+4)-5 \\)   \n",
       "2          BIDMAS             A  \\( 3 \\times(2+4)-5 \\)   \n",
       "3          BIDMAS             A  \\( 3 \\times(2+4)-5 \\)   \n",
       "4          BIDMAS             A  \\( 3 \\times(2+4)-5 \\)   \n",
       "...           ...           ...                    ...   \n",
       "15288    Rotation             B              Only Paul   \n",
       "15289    Rotation             B              Only Paul   \n",
       "15290    Rotation             B              Only Paul   \n",
       "15291    Rotation             B              Only Paul   \n",
       "15292    Rotation             B              Only Paul   \n",
       "\n",
       "                                            QuestionText WrongChoice  \\\n",
       "0      \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...           D   \n",
       "1      What placement of brackets will result in the ...           D   \n",
       "2      In the equation 3 × 2 + 4 - 5, where should br...           D   \n",
       "3      How can brackets be arranged in the expression...           D   \n",
       "4      Which locations for brackets in the expression...           D   \n",
       "...                                                  ...         ...   \n",
       "15288  Jo and Paul are arguing about how to fully des...           D   \n",
       "15289  Jo claims that the rotation from shape P to sh...           D   \n",
       "15290  According to Jo, moving from shape P to shape ...           D   \n",
       "15291  Paul argues that the transition from shape P t...           D   \n",
       "15292  Paul asserts that to rotate from shape P to sh...           D   \n",
       "\n",
       "                    WrongText  MisconceptionId QuestionId_Answer  \\\n",
       "0      Does not need brackets             1672               0_D   \n",
       "1      Does not need brackets             1672               0_D   \n",
       "2      Does not need brackets             1672               0_D   \n",
       "3      Does not need brackets             1672               0_D   \n",
       "4      Does not need brackets             1672               0_D   \n",
       "...                       ...              ...               ...   \n",
       "15288      Neither is correct               95            1868_D   \n",
       "15289      Neither is correct               95            1868_D   \n",
       "15290      Neither is correct               95            1868_D   \n",
       "15291      Neither is correct               95            1868_D   \n",
       "15292      Neither is correct               95            1868_D   \n",
       "\n",
       "       QuestionAiCreated                                   QuestionComplete  \n",
       "0                  False  Subject: BIDMAS. Construct: Use the order of o...  \n",
       "1                   True  Subject: BIDMAS. Construct: Use the order of o...  \n",
       "2                   True  Subject: BIDMAS. Construct: Use the order of o...  \n",
       "3                   True  Subject: BIDMAS. Construct: Use the order of o...  \n",
       "4                   True  Subject: BIDMAS. Construct: Use the order of o...  \n",
       "...                  ...                                                ...  \n",
       "15288              False  Subject: Rotation. Construct: Describe a 90° o...  \n",
       "15289               True  Subject: Rotation. Construct: Describe a 90° o...  \n",
       "15290               True  Subject: Rotation. Construct: Describe a 90° o...  \n",
       "15291               True  Subject: Rotation. Construct: Describe a 90° o...  \n",
       "15292               True  Subject: Rotation. Construct: Describe a 90° o...  \n",
       "\n",
       "[15293 rows x 14 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def batched_inference(model, tokenizer, texts: list[str], bs: int, desc: str) -> Tensor:\n",
    "    \"\"\"Basically SentenceTransformer.encode, but consume less vram.\"\"\"\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), bs), desc=desc):\n",
    "        # max_length=256 comes from plotting the complete question text, and 256 covers 99%\n",
    "        encoded = tokenizer(\n",
    "            texts[i : i + bs],\n",
    "            max_length=256,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(\"cuda\")\n",
    "        outputs = model(**encoded)\n",
    "        emb = outputs.last_hidden_state[:, 0]  # cls token\n",
    "        emb = F.normalize(emb, p=2, dim=-1)\n",
    "        embeddings.append(emb.cpu())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hn_mine_hf(\n",
    "#     model,\n",
    "#     tokenizer,\n",
    "#     q_texts: list[str],\n",
    "#     q_mis_ids: list[int],\n",
    "#     mis_texts: list[str],\n",
    "#     mis_ids: list[int],\n",
    "#     k: int,\n",
    "#     bs: int,\n",
    "# ) -> list[list[int]]:\n",
    "#     \"\"\"Hard negative mining, but different from: https://www.sbert.net/docs/package_reference/util.html#sentence_transformers.util.mine_hard_negatives.\n",
    "#     Sentence Transformers' version assumes different rows are always negatives, but that is not the case if we use paraphrased data.\n",
    "\n",
    "#     Args:\n",
    "#         q_texts (list[str]): Question texts.\n",
    "#         q_mis_ids (list[int]): Ground truth misconception ids for the questions.\n",
    "#         mis_texts (list[str]): Misconception texts.\n",
    "#         mis_ids (list[int]): Misconception ids.\n",
    "#         k (int): Top k hard misconception ids per question.\n",
    "#         bs (int): Batch size.\n",
    "\n",
    "#     Returns:\n",
    "#         list[list[int]]:\n",
    "#             Hard misconceptions for each question.\n",
    "#             This is NOT misconception ids, but the actual list index.\n",
    "#     \"\"\"\n",
    "#     assert len(q_texts) == len(q_mis_ids)\n",
    "#     assert len(mis_texts) == len(mis_ids)\n",
    "#     m_embeds = batched_inference(\n",
    "#         model, tokenizer, mis_texts, bs=bs, desc=\"miscon\"\n",
    "#     ).numpy()\n",
    "#     index = Index(ndim=m_embeds.shape[-1], metric=\"ip\")\n",
    "#     index.add(np.arange(m_embeds.shape[0]), m_embeds)\n",
    "#     q_embeds = batched_inference(\n",
    "#         model, tokenizer, q_texts, bs=bs, desc=\"questions\"\n",
    "#     ).numpy()\n",
    "#     batch_matches = index.search(q_embeds, count=k)\n",
    "#     hards = []\n",
    "#     for i, matches in enumerate(batch_matches):  # type: ignore\n",
    "#         nth_miscons: list[int] = [m.key for m in matches]\n",
    "#         hard_miscons = [nth for nth in nth_miscons if mis_ids[nth] != q_mis_ids[i]]\n",
    "#         hards.append(hard_miscons)\n",
    "#     assert len(hards) == len(q_texts)\n",
    "#     return hards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hn_mine_st(\n",
    "    model: SentenceTransformer,\n",
    "    q_texts: list[str],\n",
    "    q_mis_ids: list[int],\n",
    "    mis_texts: list[str],\n",
    "    mis_ids: list[int],\n",
    "    k: int,\n",
    "    bs: int,\n",
    ") -> list[list[int]]:\n",
    "    \"\"\"Hard negative mining, but different from: https://www.sbert.net/docs/package_reference/util.html#sentence_transformers.util.mine_hard_negatives.\n",
    "    Sentence Transformers' version assumes different rows are always negatives, but that is not the case if we use paraphrased data.\n",
    "\n",
    "    Args:\n",
    "        q_texts (list[str]): Question texts.\n",
    "        q_mis_ids (list[int]): Ground truth misconception ids for the questions.\n",
    "        mis_texts (list[str]): Misconception texts.\n",
    "        mis_ids (list[int]): Misconception ids.\n",
    "        k (int): Top k hard misconception ids per question (at max).\n",
    "        bs (int): Batch size.\n",
    "\n",
    "    Returns:\n",
    "        list[list[int]]:\n",
    "            Hard misconceptions for each question.\n",
    "            This is NOT misconception ids, but the actual list index.\n",
    "    \"\"\"\n",
    "    assert len(q_texts) == len(q_mis_ids)\n",
    "    assert len(mis_texts) == len(mis_ids)\n",
    "    m_embeds = model.encode(\n",
    "        mis_texts,\n",
    "        batch_size=bs,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=True,\n",
    "        device=\"cuda\",\n",
    "    )\n",
    "    index = Index(ndim=m_embeds.shape[-1], metric=\"ip\")\n",
    "    index.add(np.arange(m_embeds.shape[0]), m_embeds)\n",
    "    q_embeds = model.encode(\n",
    "        q_texts,\n",
    "        batch_size=bs,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=True,\n",
    "        device=\"cuda\",\n",
    "    )\n",
    "    batch_matches = index.search(q_embeds, count=k)\n",
    "    hards = []\n",
    "    for i, matches in enumerate(batch_matches):  # type: ignore\n",
    "        nth_miscons = [m.key for m in matches]\n",
    "        hard_miscons = [\n",
    "            nth.item() for nth in nth_miscons if mis_ids[nth] != q_mis_ids[i]\n",
    "        ]\n",
    "        hards.append(hard_miscons)\n",
    "    assert len(hards) == len(q_texts)\n",
    "    return hards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hards = hn_mine_hf(\n",
    "#     model_,\n",
    "#     tokenizer_,\n",
    "#     q_texts=df_q[\"QuestionComplete\"].tolist(),\n",
    "#     q_mis_ids=df_q[\"MisconceptionId\"].tolist(),\n",
    "#     mis_texts=df_m[\"MisconceptionText\"].tolist(),\n",
    "#     mis_ids=df_m[\"MisconceptionId\"].tolist(),\n",
    "#     k=100,\n",
    "#     bs=16,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = Path(\"hards.json\")\n",
    "if cache.exists():\n",
    "    print(\"loading from cache\")\n",
    "    with open(cache, \"r\") as f:\n",
    "        hards_st = json.load(f)\n",
    "else:\n",
    "    print(\"no cache, precomputing\")\n",
    "    hards_st = hn_mine_st(\n",
    "        model,\n",
    "        q_texts=df_train[\"QuestionComplete\"].tolist(),\n",
    "        q_mis_ids=df_train[\"MisconceptionId\"].tolist(),\n",
    "        mis_texts=df_mis[\"MisconceptionText\"].tolist(),\n",
    "        mis_ids=df_mis[\"MisconceptionId\"].tolist(),\n",
    "        k=100,\n",
    "        bs=4,\n",
    "    )\n",
    "    with open(cache, \"w\") as f:\n",
    "        json.dump(hards_st, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['q', 'mis', 'neg_1', 'neg_2', 'neg_3', 'neg_4', 'neg_5', 'neg_6', 'neg_7', 'neg_8', 'neg_9', 'neg_10'],\n",
       "    num_rows: 15293\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_mnr_dataset(\n",
    "    q_texts: list[str],\n",
    "    q_mis_ids: list[int],\n",
    "    mis_texts: list[str],\n",
    "    mis_ids: list[int],\n",
    "    hards: list[list[int]],\n",
    "    n_negatives: int,\n",
    ") -> HFDataset:\n",
    "    \"\"\"Create SentenceTransformer dataset suitable for MultipleNegativesRankingLoss.\n",
    "    The format is (anchor, positive, negative_1, …, negative_n).\n",
    "    Example: https://huggingface.co/datasets/tomaarsen/gooaq-hard-negatives\n",
    "    \"\"\"\n",
    "    assert len(q_texts) == len(q_mis_ids) == len(hards)\n",
    "    assert len(mis_texts) == len(mis_ids)\n",
    "    assert all(n_negatives <= len(hard) for hard in hards)\n",
    "    # create reverse mapping\n",
    "    mis_id_to_mis_idx = defaultdict(list)\n",
    "    for i, mis_id in enumerate(mis_ids):\n",
    "        mis_id_to_mis_idx[mis_id].append(i)\n",
    "    # make hf dataset\n",
    "    d = {}\n",
    "    d[\"q\"], d[\"mis\"] = [], []\n",
    "    for i in range(1, n_negatives + 1):\n",
    "        d[f\"neg_{i}\"] = []\n",
    "    for i, (q_text, q_mis_id) in enumerate(zip(q_texts, q_mis_ids)):\n",
    "        rand_pos = random.choice(mis_id_to_mis_idx[q_mis_id])\n",
    "        rand_negs = random.sample(hards[i], k=n_negatives)\n",
    "        d[\"q\"].append(q_text)\n",
    "        d[\"mis\"].append(mis_texts[rand_pos])\n",
    "        for j, rand_neg in enumerate(rand_negs, 1):\n",
    "            d[f\"neg_{j}\"].append(mis_texts[rand_neg])\n",
    "    return HFDataset.from_dict(d)\n",
    "\n",
    "\n",
    "ds = make_mnr_dataset(\n",
    "    q_texts=df_train[\"QuestionComplete\"].tolist(),\n",
    "    q_mis_ids=df_train[\"MisconceptionId\"].tolist(),\n",
    "    mis_texts=df_mis[\"MisconceptionText\"].tolist(),\n",
    "    mis_ids=df_mis[\"MisconceptionId\"].tolist(),\n",
    "    hards=hards_st,\n",
    "    n_negatives=10,\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['q', 'mis', 'label'],\n",
       "    num_rows: 168223\n",
       "})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_cosent_dataset(\n",
    "    q_texts: list[str],\n",
    "    q_mis_ids: list[int],\n",
    "    mis_texts: list[str],\n",
    "    mis_ids: list[int],\n",
    "    hards: list[list[int]],\n",
    "    n_negatives: int,\n",
    ") -> HFDataset:\n",
    "    \"\"\"Create SentenceTransformer dataset suitable for CoSENTLoss.\n",
    "    The format is (sentence_A, sentence_B).\n",
    "    Example: https://sbert.net/docs/sentence_transformer/training_overview.html#loss-function\n",
    "    \"\"\"\n",
    "    assert len(q_texts) == len(q_mis_ids) == len(hards)\n",
    "    assert len(mis_texts) == len(mis_ids)\n",
    "    assert all(n_negatives <= len(hard) for hard in hards)\n",
    "    # create reverse mapping\n",
    "    mis_id_to_mis_idx = defaultdict(list)\n",
    "    for i, mis_id in enumerate(mis_ids):\n",
    "        mis_id_to_mis_idx[mis_id].append(i)\n",
    "    # make hf dataset\n",
    "    d = {\"q\": [], \"mis\": [], \"label\": []}\n",
    "    for i, (q_text, q_mis_id) in enumerate(zip(q_texts, q_mis_ids)):\n",
    "        # insert positive\n",
    "        rand_pos = random.choice(mis_id_to_mis_idx[q_mis_id])\n",
    "        d[\"q\"].append(q_text)\n",
    "        d[\"mis\"].append(mis_texts[rand_pos])\n",
    "        d[\"label\"].append(1.0)\n",
    "        # insert negatives\n",
    "        rand_negs = random.sample(hards[i], k=n_negatives)\n",
    "        for j, rand_neg in enumerate(rand_negs, 1):\n",
    "            d[\"q\"].append(q_text)\n",
    "            d[\"mis\"].append(mis_texts[rand_neg])\n",
    "            d[\"label\"].append(-1.0)\n",
    "    return HFDataset.from_dict(d)\n",
    "\n",
    "\n",
    "ds2 = make_cosent_dataset(\n",
    "    q_texts=df_train[\"QuestionComplete\"].tolist(),\n",
    "    q_mis_ids=df_train[\"MisconceptionId\"].tolist(),\n",
    "    mis_texts=df_mis[\"MisconceptionText\"].tolist(),\n",
    "    mis_ids=df_mis[\"MisconceptionId\"].tolist(),\n",
    "    hards=hards_st,\n",
    "    n_negatives=10,\n",
    ")\n",
    "ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ir_evaluator_dataset(\n",
    "    df_val: pd.DataFrame, orig_mis: list[str]\n",
    ") -> tuple[dict, dict, dict]:\n",
    "    assert len(orig_mis) == 2587\n",
    "    mapping = (\n",
    "        df_val[[\"QuestionId_Answer\", \"MisconceptionId\"]]\n",
    "        .set_index(\"QuestionId_Answer\")[\"MisconceptionId\"]\n",
    "        .apply(lambda x: [x])\n",
    "        .to_dict()\n",
    "    )\n",
    "    q = (\n",
    "        df_val[[\"QuestionId_Answer\", \"QuestionComplete\"]]\n",
    "        .set_index(\"QuestionId_Answer\")[\"QuestionComplete\"]\n",
    "        .to_dict()\n",
    "    )\n",
    "    mis = {i: mis_text for i, mis_text in enumerate(orig_mis)}\n",
    "    return q, mis, mapping\n",
    "\n",
    "\n",
    "q, mis, mapping = make_ir_evaluator_dataset(df_val, orig_mis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9403e01a57648bd9dea145cea3ce73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:13<00:00, 13.54s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluator = InformationRetrievalEvaluator(\n",
    "    queries=q,\n",
    "    corpus=mis,\n",
    "    relevant_docs=mapping,\n",
    "    map_at_k=[1, 3, 5, 10, 25],\n",
    "    batch_size=4,\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "results = evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cosine_accuracy@1': 0.07006854531607007,\n",
       " 'cosine_accuracy@3': 0.1728865194211729,\n",
       " 'cosine_accuracy@5': 0.24523990860624523,\n",
       " 'cosine_accuracy@10': 0.361005331302361,\n",
       " 'cosine_precision@1': 0.07006854531607007,\n",
       " 'cosine_precision@3': 0.05762883980705762,\n",
       " 'cosine_precision@5': 0.04904798172124905,\n",
       " 'cosine_precision@10': 0.036100533130236104,\n",
       " 'cosine_recall@1': 0.07006854531607007,\n",
       " 'cosine_recall@3': 0.1728865194211729,\n",
       " 'cosine_recall@5': 0.24523990860624523,\n",
       " 'cosine_recall@10': 0.361005331302361,\n",
       " 'cosine_ndcg@10': 0.19553563097479792,\n",
       " 'cosine_mrr@10': 0.14515588921529496,\n",
       " 'cosine_map@1': 0.07006854531607007,\n",
       " 'cosine_map@3': 0.11398832190911398,\n",
       " 'cosine_map@5': 0.13005839045443005,\n",
       " 'cosine_map@10': 0.14515588921529515,\n",
       " 'cosine_map@25': 0.1540876920346375,\n",
       " 'dot_accuracy@1': 0.07083015993907082,\n",
       " 'dot_accuracy@3': 0.1782178217821782,\n",
       " 'dot_accuracy@5': 0.2421934501142422,\n",
       " 'dot_accuracy@10': 0.3602437166793602,\n",
       " 'dot_precision@1': 0.07083015993907082,\n",
       " 'dot_precision@3': 0.0594059405940594,\n",
       " 'dot_precision@5': 0.04843869002284844,\n",
       " 'dot_precision@10': 0.036024371667936025,\n",
       " 'dot_recall@1': 0.07083015993907082,\n",
       " 'dot_recall@3': 0.1782178217821782,\n",
       " 'dot_recall@5': 0.2421934501142422,\n",
       " 'dot_recall@10': 0.3602437166793602,\n",
       " 'dot_ndcg@10': 0.19759664717151854,\n",
       " 'dot_mrr@10': 0.14790918652304777,\n",
       " 'dot_map@1': 0.07083015993907082,\n",
       " 'dot_map@3': 0.11779639502411779,\n",
       " 'dot_map@5': 0.13222899212998224,\n",
       " 'dot_map@10': 0.14790918652304788,\n",
       " 'dot_map@25': 0.15751345921931273}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw training, move this to script, and make cached hn mining because we will hammer the script a LOT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    SentenceTransformerModelCardData,\n",
    ")\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "\n",
    "# 1. Load a model to finetune with 2. (Optional) model card data\n",
    "# -- done upper\n",
    "\n",
    "# 3. Load a dataset to finetune on\n",
    "dataset = load_dataset(\"sentence-transformers/all-nli\", \"triplet\")\n",
    "# -- done upper \n",
    "\n",
    "# 4. Define a loss function\n",
    "loss = MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# 5. (Optional) Specify training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"models/gte-large-en-1\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    run_name=\"gte-large-en-1\",  # Will be used in W&B if `wandb` is installed\n",
    ")\n",
    "\n",
    "# 6. (Optional) Create an evaluator & evaluate the base model\n",
    "# dev_evaluator = TripletEvaluator(\n",
    "#     anchors=eval_dataset[\"anchor\"],\n",
    "#     positives=eval_dataset[\"positive\"],\n",
    "#     negatives=eval_dataset[\"negative\"],\n",
    "#     name=\"all-nli-dev\",\n",
    "# )\n",
    "# dev_evaluator(model)\n",
    "\n",
    "# 7. Create a trainer & train\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds2,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=dev_evaluator,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "# (Optional) Evaluate the trained model on the test set\n",
    "test_evaluator = TripletEvaluator(\n",
    "    anchors=test_dataset[\"anchor\"],\n",
    "    positives=test_dataset[\"positive\"],\n",
    "    negatives=test_dataset[\"negative\"],\n",
    "    name=\"all-nli-test\",\n",
    ")\n",
    "test_evaluator(model)\n",
    "\n",
    "# 8. Save the trained model\n",
    "model.save_pretrained(\"models/mpnet-base-all-nli-triplet/final\")\n",
    "\n",
    "# 9. (Optional) Push it to the Hugging Face Hub\n",
    "model.push_to_hub(\"mpnet-base-all-nli-triplet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ef95dc8bb2401799b193a280c7cdc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0000.parquet:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12d971b45d7401987373ebe913c1f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0001.parquet:   0%|          | 0.00/95.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03013e47f3c140929290c9dc79b056eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating corpus split:   0%|          | 0/382545 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb0b1a5d817431688efc276b6c736d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "queries/queries/0000.parquet:   0%|          | 0.00/3.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f0e495d080449b97b02af6ac04a977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating queries split:   0%|          | 0/49 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fdb538b9d34fc987aed42a4fc471ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/14.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c33001033734aeb86145e363eaf97b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.tsv:   0%|          | 0.00/101k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14da0569c607434e82711a4bc004a179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2214 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de62a2c08594acebd4ca668369e2c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/382545 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9cecca6bc748e6936b35f8938dbe06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/382545 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BeIR-touche2020-subset-test_cosine_map@100\n",
      "0.30561077016600136\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load a model\n",
    "modelmini = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Load the Touche-2020 IR dataset (https://huggingface.co/datasets/BeIR/webis-touche2020, https://huggingface.co/datasets/BeIR/webis-touche2020-qrels)\n",
    "corpus = load_dataset(\"BeIR/webis-touche2020\", \"corpus\", split=\"corpus\")\n",
    "queries = load_dataset(\"BeIR/webis-touche2020\", \"queries\", split=\"queries\")\n",
    "relevant_docs_data = load_dataset(\"BeIR/webis-touche2020-qrels\", split=\"test\")\n",
    "\n",
    "# For this dataset, we want to concatenate the title and texts for the corpus\n",
    "corpus = corpus.map(lambda x: {'text': x['title'] + \" \" + x['text']}, remove_columns=['title'])\n",
    "\n",
    "# Shrink the corpus size heavily to only the relevant documents + 30,000 random documents\n",
    "required_corpus_ids = set(map(str, relevant_docs_data[\"corpus-id\"]))\n",
    "required_corpus_ids |= set(random.sample(corpus[\"_id\"], k=30_000))\n",
    "corpus = corpus.filter(lambda x: x[\"_id\"] in required_corpus_ids)\n",
    "\n",
    "# Convert the datasets to dictionaries\n",
    "corpus = dict(zip(corpus[\"_id\"], corpus[\"text\"]))  # Our corpus (cid => document)\n",
    "queries = dict(zip(queries[\"_id\"], queries[\"text\"]))  # Our queries (qid => question)\n",
    "relevant_docs = {}  # Query ID to relevant documents (qid => set([relevant_cids])\n",
    "for qid, corpus_ids in zip(relevant_docs_data[\"query-id\"], relevant_docs_data[\"corpus-id\"]):\n",
    "    qid = str(qid)\n",
    "    corpus_ids = str(corpus_ids)\n",
    "    if qid not in relevant_docs:\n",
    "        relevant_docs[qid] = set()\n",
    "    relevant_docs[qid].add(corpus_ids)\n",
    "\n",
    "# Given queries, a corpus and a mapping with relevant documents, the InformationRetrievalEvaluator computes different IR metrics.\n",
    "ir_evaluator = InformationRetrievalEvaluator(\n",
    "    queries=queries,\n",
    "    corpus=corpus,\n",
    "    relevant_docs=relevant_docs,\n",
    "    name=\"BeIR-touche2020-subset-test\",\n",
    ")\n",
    "results = ir_evaluator(modelmini)\n",
    "'''\n",
    "Information Retrieval Evaluation of the model on the BeIR-touche2020-test dataset:\n",
    "Queries: 49\n",
    "Corpus: 31923\n",
    "\n",
    "Score-Function: cosine\n",
    "Accuracy@1: 77.55%\n",
    "Accuracy@3: 93.88%\n",
    "Accuracy@5: 97.96%\n",
    "Accuracy@10: 100.00%\n",
    "Precision@1: 77.55%\n",
    "Precision@3: 72.11%\n",
    "Precision@5: 71.43%\n",
    "Precision@10: 62.65%\n",
    "Recall@1: 1.72%\n",
    "Recall@3: 4.78%\n",
    "Recall@5: 7.90%\n",
    "Recall@10: 13.86%\n",
    "MRR@10: 0.8580\n",
    "NDCG@10: 0.6606\n",
    "MAP@100: 0.2934\n",
    "'''\n",
    "print(ir_evaluator.primary_metric)\n",
    "# => \"BeIR-touche2020-test_cosine_map@100\"\n",
    "print(results[ir_evaluator.primary_metric])\n",
    "# => 0.29335196224364596"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO this shit is taking so much time lol\n",
    "# * the minconception must come from ALL dataset\n",
    "# * but the\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2cfe56d1b0a479fa5daec57ca629f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "results = evaluator(modelmini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_eedi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
