{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sentence_transformers.losses import CoSENTLoss, MultipleNegativesRankingLoss\n",
    "from datasets import Dataset as HFDataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from usearch.index import Index\n",
    "import string\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "anchors = []\n",
    "positives = []\n",
    "# Open a file, do preprocessing, filtering, cleaning, etc.\n",
    "# and append to the lists\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"anchor\": anchors,\n",
    "    \"positive\": positives,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_name = \"Alibaba-NLP/gte-large-en-v1.5\"\n",
    "model = SentenceTransformer(model_name, trust_remote_code=True)\n",
    "model_ = AutoModel.from_pretrained(model_name, trust_remote_code=True).cuda()\n",
    "tokenizer_ = AutoTokenizer.from_pretrained(model_name)\n",
    "# load data\n",
    "df = pd.read_csv(\"data/eedi-paraphrased/train.csv\")\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.7, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(df, groups=df[\"QuestionId\"]))\n",
    "df_train = df.iloc[train_idx]\n",
    "df_val = df.iloc[val_idx]\n",
    "df_val = df_val[~df_val[\"QuestionAiCreated\"] & ~df_val[\"MisconceptionAiCreated\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q = df_train[\n",
    "    [\n",
    "        \"ConstructName\",\n",
    "        \"SubjectName\",\n",
    "        \"QuestionId_Answer\",\n",
    "        \"QuestionText\",\n",
    "        \"WrongText\",\n",
    "        \"CorrectText\",\n",
    "        \"MisconceptionId\",\n",
    "    ]\n",
    "].drop_duplicates()\n",
    "df_q[\"QuestionComplete\"] = (\n",
    "    \"Subject: \"\n",
    "    + df_q[\"SubjectName\"]\n",
    "    + \". Construct: \"\n",
    "    + df_q[\"ConstructName\"]\n",
    "    + \". Question: \"\n",
    "    + df_q[\"QuestionText\"]\n",
    "    + \". Correct answer: \"\n",
    "    + df_q[\"CorrectText\"]\n",
    "    + \". Wrong answer: \"\n",
    "    + df_q[\"WrongText\"]\n",
    "    + \".\"\n",
    ")\n",
    "df_q = (\n",
    "    df_q[[\"MisconceptionId\", \"QuestionComplete\"]]\n",
    "    .sort_values(\"MisconceptionId\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = df[[\"MisconceptionId\", \"MisconceptionText\"]].sort_values(\"MisconceptionId\").drop_duplicates().reset_index(drop=True)\n",
    "df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def batched_inference(model, tokenizer, texts: list[str], bs: int, desc: str) -> Tensor:\n",
    "    \"\"\"Basically SentenceTransformer.encode, but consume less vram.\"\"\"\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), bs), desc=desc):\n",
    "        # max_length=256 comes from plotting the complete question text, and 256 covers 99%\n",
    "        encoded = tokenizer(\n",
    "            texts[i : i + bs],\n",
    "            max_length=256,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(\"cuda\")\n",
    "        outputs = model(**encoded)\n",
    "        emb = outputs.last_hidden_state[:, 0]  # cls token\n",
    "        emb = F.normalize(emb, p=2, dim=-1)\n",
    "        embeddings.append(emb.cpu())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hn_mine_hf(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    q_texts: list[str],\n",
    "    q_mis_ids: list[int],\n",
    "    mis_texts: list[str],\n",
    "    mis_ids: list[int],\n",
    "    k: int,\n",
    "    bs: int,\n",
    ") -> list[list[int]]:\n",
    "    \"\"\"Hard negative mining, but different from: https://www.sbert.net/docs/package_reference/util.html#sentence_transformers.util.mine_hard_negatives.\n",
    "    Sentence Transformers' version assumes different rows are always negatives, but that is not the case if we use paraphrased data.\n",
    "\n",
    "    Args:\n",
    "        q_texts (list[str]): Question texts.\n",
    "        q_mis_ids (list[int]): Ground truth misconception ids for the questions.\n",
    "        mis_texts (list[str]): Misconception texts.\n",
    "        mis_ids (list[int]): Misconception ids.\n",
    "        k (int): Top k hard misconception ids per question.\n",
    "        bs (int): Batch size.\n",
    "\n",
    "    Returns:\n",
    "        list[list[int]]:\n",
    "            Hard misconceptions for each question.\n",
    "            This is NOT misconception ids, but the actual list index.\n",
    "    \"\"\"\n",
    "    assert len(q_texts) == len(q_mis_ids)\n",
    "    assert len(mis_texts) == len(mis_ids)\n",
    "    m_embeds = batched_inference(\n",
    "        model, tokenizer, mis_texts, bs=bs, desc=\"miscon\"\n",
    "    ).numpy()\n",
    "    index = Index(ndim=m_embeds.shape[-1], metric=\"ip\")\n",
    "    index.add(np.arange(m_embeds.shape[0]), m_embeds)\n",
    "    q_embeds = batched_inference(\n",
    "        model, tokenizer, q_texts, bs=bs, desc=\"questions\"\n",
    "    ).numpy()\n",
    "    batch_matches = index.search(q_embeds, count=k)\n",
    "    hards = []\n",
    "    for i, matches in enumerate(batch_matches):  # type: ignore\n",
    "        nth_miscons: list[int] = [m.key for m in matches]\n",
    "        hard_miscons = [nth for nth in nth_miscons if mis_ids[nth] != q_mis_ids[i]]\n",
    "        hards.append(hard_miscons)\n",
    "    assert len(hards) == len(q_texts)\n",
    "    return hards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hn_mine_st(\n",
    "    model: SentenceTransformer,\n",
    "    q_texts: list[str],\n",
    "    q_mis_ids: list[int],\n",
    "    mis_texts: list[str],\n",
    "    mis_ids: list[int],\n",
    "    k: int,\n",
    "    bs: int,\n",
    ") -> list[list[int]]:\n",
    "    \"\"\"Hard negative mining, but different from: https://www.sbert.net/docs/package_reference/util.html#sentence_transformers.util.mine_hard_negatives.\n",
    "    Sentence Transformers' version assumes different rows are always negatives, but that is not the case if we use paraphrased data.\n",
    "\n",
    "    Args:\n",
    "        q_texts (list[str]): Question texts.\n",
    "        q_mis_ids (list[int]): Ground truth misconception ids for the questions.\n",
    "        mis_texts (list[str]): Misconception texts.\n",
    "        mis_ids (list[int]): Misconception ids.\n",
    "        k (int): Top k hard misconception ids per question (at max).\n",
    "        bs (int): Batch size.\n",
    "\n",
    "    Returns:\n",
    "        list[list[int]]:\n",
    "            Hard misconceptions for each question.\n",
    "            This is NOT misconception ids, but the actual list index.\n",
    "    \"\"\"\n",
    "    assert len(q_texts) == len(q_mis_ids)\n",
    "    assert len(mis_texts) == len(mis_ids)\n",
    "    m_embeds = model.encode(\n",
    "        mis_texts,\n",
    "        batch_size=bs,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=True,\n",
    "        device=\"cuda\",\n",
    "    )\n",
    "    index = Index(ndim=m_embeds.shape[-1], metric=\"ip\")\n",
    "    index.add(np.arange(m_embeds.shape[0]), m_embeds)\n",
    "    q_embeds = model.encode(\n",
    "        q_texts,\n",
    "        batch_size=bs,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=True,\n",
    "        device=\"cuda\",\n",
    "    )\n",
    "    batch_matches = index.search(q_embeds, count=k)\n",
    "    hards = []\n",
    "    for i, matches in enumerate(batch_matches):  # type: ignore\n",
    "        nth_miscons: list[int] = [m.key for m in matches]\n",
    "        hard_miscons = [nth for nth in nth_miscons if mis_ids[nth] != q_mis_ids[i]]\n",
    "        hards.append(hard_miscons)\n",
    "    assert len(hards) == len(q_texts)\n",
    "    return hards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hards = hn_mine_hf(\n",
    "    model_,\n",
    "    tokenizer_,\n",
    "    q_texts=df_q[\"QuestionComplete\"].tolist(),\n",
    "    q_mis_ids=df_q[\"MisconceptionId\"].tolist(),\n",
    "    mis_texts=df_m[\"MisconceptionText\"].tolist(),\n",
    "    mis_ids=df_m[\"MisconceptionId\"].tolist(),\n",
    "    k=100,\n",
    "    bs=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hards_st = hn_mine_st(\n",
    "    model,\n",
    "    q_texts=df_q[\"QuestionComplete\"].tolist(),\n",
    "    q_mis_ids=df_q[\"MisconceptionId\"].tolist(),\n",
    "    mis_texts=df_m[\"MisconceptionText\"].tolist(),\n",
    "    mis_ids=df_m[\"MisconceptionId\"].tolist(),\n",
    "    k=100,\n",
    "    bs=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mnr_dataset(\n",
    "    q_texts: list[str],\n",
    "    q_mis_ids: list[int],\n",
    "    mis_texts: list[str],\n",
    "    mis_ids: list[int],\n",
    "    hards: list[list[int]],\n",
    "    n_negatives: int,\n",
    ") -> HFDataset:\n",
    "    \"\"\"Create SentenceTransformer dataset suitable for MultipleNegativesRankingLoss.\n",
    "    The format is (anchor, positive, negative_1, …, negative_n).\n",
    "    Example: https://huggingface.co/datasets/tomaarsen/gooaq-hard-negatives\n",
    "    \"\"\"\n",
    "    assert len(q_texts) == len(q_mis_ids) == len(hards)\n",
    "    assert len(mis_texts) == len(mis_ids)\n",
    "    assert all(n_negatives <= len(hard) for hard in hards)\n",
    "    # create reverse mapping\n",
    "    mis_id_to_mis_idx = defaultdict(list)\n",
    "    for i, mis_id in enumerate(mis_ids):\n",
    "        mis_id_to_mis_idx[mis_id].append(i)\n",
    "    # make hf dataset\n",
    "    d = {}\n",
    "    d[\"q\"], d[\"mis\"] = [], []\n",
    "    for i in range(1, n_negatives + 1):\n",
    "        d[f\"neg_{i}\"] = []\n",
    "    for i, (q_text, q_mis_id) in enumerate(zip(q_texts, q_mis_ids)):\n",
    "        rand_pos = random.choice(mis_id_to_mis_idx[q_mis_id])\n",
    "        rand_negs = random.sample(hards[i], k=n_negatives)\n",
    "        d[\"q\"].append(q_text)\n",
    "        d[\"mis\"].append(mis_texts[rand_pos])\n",
    "        for j, rand_neg in enumerate(rand_negs, 1):\n",
    "            d[f\"neg_{j}\"].append(mis_texts[rand_neg])\n",
    "    return HFDataset.from_dict(d)\n",
    "\n",
    "\n",
    "ds = make_mnr_dataset(\n",
    "    q_texts=df_q[\"QuestionComplete\"].tolist(),\n",
    "    q_mis_ids=df_q[\"MisconceptionId\"].tolist(),\n",
    "    mis_texts=df_m[\"MisconceptionText\"].tolist(),\n",
    "    mis_ids=df_m[\"MisconceptionId\"].tolist(),\n",
    "    hards=hards,\n",
    "    n_negatives=10,\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cosent_dataset(\n",
    "    q_texts: list[str],\n",
    "    q_mis_ids: list[int],\n",
    "    mis_texts: list[str],\n",
    "    mis_ids: list[int],\n",
    "    hards: list[list[int]],\n",
    "    n_negatives: int,\n",
    ") -> HFDataset:\n",
    "    \"\"\"Create SentenceTransformer dataset suitable for CoSENTLoss.\n",
    "    The format is (sentence_A, sentence_B).\n",
    "    Example: https://sbert.net/docs/sentence_transformer/training_overview.html#loss-function\n",
    "    \"\"\"\n",
    "    assert len(q_texts) == len(q_mis_ids) == len(hards)\n",
    "    assert len(mis_texts) == len(mis_ids)\n",
    "    assert all(n_negatives <= len(hard) for hard in hards)\n",
    "    # create reverse mapping\n",
    "    mis_id_to_mis_idx = defaultdict(list)\n",
    "    for i, mis_id in enumerate(mis_ids):\n",
    "        mis_id_to_mis_idx[mis_id].append(i)\n",
    "    # make hf dataset\n",
    "    d = {\"q\": [], \"mis\": [], \"label\": []}\n",
    "    for i, (q_text, q_mis_id) in enumerate(zip(q_texts, q_mis_ids)):\n",
    "        # insert positive\n",
    "        rand_pos = random.choice(mis_id_to_mis_idx[q_mis_id])\n",
    "        d[\"q\"].append(q_text)\n",
    "        d[\"mis\"].append(mis_texts[rand_pos])\n",
    "        d[\"label\"].append(1.0)\n",
    "        # insert negatives\n",
    "        rand_negs = random.sample(hards[i], k=n_negatives)\n",
    "        for j, rand_neg in enumerate(rand_negs, 1):\n",
    "            d[\"q\"].append(q_text)\n",
    "            d[\"mis\"].append(mis_texts[rand_neg])\n",
    "            d[\"label\"].append(-1.0)\n",
    "    return HFDataset.from_dict(d)\n",
    "\n",
    "\n",
    "ds = make_cosent_dataset(\n",
    "    q_texts=df_q[\"QuestionComplete\"].tolist(),\n",
    "    q_mis_ids=df_q[\"MisconceptionId\"].tolist(),\n",
    "    mis_texts=df_m[\"MisconceptionText\"].tolist(),\n",
    "    mis_ids=df_m[\"MisconceptionId\"].tolist(),\n",
    "    hards=hards,\n",
    "    n_negatives=10,\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_eedi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
