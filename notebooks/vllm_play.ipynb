{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-05 21:14:31 config.py:350] This model supports multiple tasks: {'generate', 'embedding'}. Defaulting to 'generate'.\n",
      "INFO 12-05 21:14:31 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='Qwen/Qwen2.5-Math-1.5B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-Math-1.5B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-Math-1.5B-Instruct, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)\n",
      "INFO 12-05 21:14:33 selector.py:135] Using Flash Attention backend.\n",
      "INFO 12-05 21:14:33 model_runner.py:1072] Starting to load model Qwen/Qwen2.5-Math-1.5B-Instruct...\n",
      "INFO 12-05 21:14:34 weight_utils.py:243] Using model weights format ['*.safetensors']\n",
      "INFO 12-05 21:14:34 weight_utils.py:288] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8df37173254e518db9945e9c309094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-05 21:14:37 model_runner.py:1077] Loading model weights took 2.8797 GB\n",
      "INFO 12-05 21:14:38 worker.py:232] Memory profiling results: total_gpu_memory=11.64GiB initial_memory_usage=3.91GiB peak_torch_memory=4.28GiB memory_usage_post_profile=4.02GiB non_torch_memory=1.13GiB kv_cache_size=5.07GiB gpu_memory_utilization=0.90\n",
      "INFO 12-05 21:14:38 gpu_executor.py:113] # GPU blocks: 11856, # CPU blocks: 9362\n",
      "INFO 12-05 21:14:38 gpu_executor.py:117] Maximum concurrency for 4096 tokens per request: 46.31x\n",
      "INFO 12-05 21:14:40 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-05 21:14:40 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-05 21:14:49 model_runner.py:1518] Graph capturing finished in 9 secs, took 0.10 GiB\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(\"Qwen/Qwen2.5-Math-1.5B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 4/4 [00:00<00:00, 15.80it/s, est. speed input: 142.20 toks/s, output: 252.80 toks/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[RequestOutput(request_id=12, prompt='the square root of 10 is', prompt_token_ids=[1782, 9334, 3704, 315, 220, 16, 15, 374], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' a rational number**\\n\\nTo determine if the square root of 10 is a', token_ids=(264, 24438, 1372, 56177, 1249, 8253, 421, 279, 9334, 3704, 315, 220, 16, 15, 374, 264), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1733408470.6773493, last_token_time=1733408470.6773493, first_scheduled_time=1733408470.6788874, first_token_time=1733408470.7134612, time_in_queue=0.0015380382537841797, finished_time=1733408470.919343, scheduler_time=0.001847956000801787, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0),\n",
       " RequestOutput(request_id=13, prompt='what does a**2 + b**2 equals to according to pythagoras?', prompt_token_ids=[12555, 1558, 264, 334, 17, 488, 293, 334, 17, 16819, 311, 4092, 311, 4510, 95362, 64647, 30], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' According to the Pythagorean theorem, in a right-angled triangle, the', token_ids=(10548, 311, 279, 5355, 95362, 45195, 57817, 11, 304, 264, 1290, 12, 38940, 21495, 11, 279), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1733408470.6777506, last_token_time=1733408470.6777506, first_scheduled_time=1733408470.6788874, first_token_time=1733408470.7134612, time_in_queue=0.00113677978515625, finished_time=1733408470.9193504, scheduler_time=0.001847956000801787, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0),\n",
       " RequestOutput(request_id=14, prompt='What is elliptic curve?', prompt_token_ids=[3838, 374, 77783, 292, 15655, 30], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Elliptic curves are algebraic structures defined over a field, which can be', token_ids=(13542, 11442, 292, 35933, 525, 46876, 292, 14389, 4512, 916, 264, 2070, 11, 892, 646, 387), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1733408470.6779509, last_token_time=1733408470.6779509, first_scheduled_time=1733408470.6788874, first_token_time=1733408470.7134612, time_in_queue=0.0009365081787109375, finished_time=1733408470.919355, scheduler_time=0.001847956000801787, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0),\n",
       " RequestOutput(request_id=15, prompt='What is prime number?', prompt_token_ids=[3838, 374, 10250, 1372, 30], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' A prime number is a natural number greater than 1 that has no positive div', token_ids=(362, 10250, 1372, 374, 264, 5810, 1372, 7046, 1091, 220, 16, 429, 702, 902, 6785, 3429), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1733408470.6781237, last_token_time=1733408470.6781237, first_scheduled_time=1733408470.6788874, first_token_time=1733408470.7134612, time_in_queue=0.0007636547088623047, finished_time=1733408470.9193592, scheduler_time=0.001847956000801787, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"the square root of 10 is\",\n",
    "    \"what does a**2 + b**2 equals to according to pythagoras?\",\n",
    "    \"What is elliptic curve?\",\n",
    "    \"What is prime number?\",\n",
    "]\n",
    "sampling_params = SamplingParams(temperature=0.8, top_p=0.95)\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'the square root of 10 is', Generated text: ' a rational number**\\n\\nTo determine if the square root of 10 is a'\n",
      "Prompt: 'what does a**2 + b**2 equals to according to pythagoras?', Generated text: ' According to the Pythagorean theorem, in a right-angled triangle, the'\n",
      "Prompt: 'What is elliptic curve?', Generated text: ' Elliptic curves are algebraic structures defined over a field, which can be'\n",
      "Prompt: 'What is prime number?', Generated text: ' A prime number is a natural number greater than 1 that has no positive div'\n"
     ]
    }
   ],
   "source": [
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_eedi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
